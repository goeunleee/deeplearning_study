{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝2일.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpI0fAgHKAx1c2CnTP6P/n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goeunleee/deeplearning_stuey/blob/master/%EB%94%A5%EB%9F%AC%EB%8B%9D2%EC%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oQgTxLjX7kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path\n",
        "\n",
        "#######################################################\n",
        "\n",
        "import pandas as pd\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t',  sep=\" \", skipinitialspace=True)\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()\n",
        "\n",
        "#######################################################\n",
        "# 결측치 확인하기\n",
        "dataset.isna().sum()\n",
        "\n",
        "# 결측치 제거하기\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "\n",
        "# Origin열을 범주형 원-핫 엔코딩 변환\n",
        "origin = dataset.pop('Origin')  # Origin컬럼을 삭제하고 origin에 보관\n",
        "\n",
        "dataset['USA'] = (origin == 1) * 0.1\n",
        "dataset['Europe'] = (origin == 2) * 0.1\n",
        "dataset['Japan'] = (origin == 3) * 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcP2L_oeYblZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "1d105030-344b-4000-9a09-7b225c7ef1a8"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>USA</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    MPG  Cylinders  Displacement  Horsepower  ...  Model Year  USA  Europe  Japan\n",
              "0  18.0          8         307.0       130.0  ...          70  0.1     0.0    0.0\n",
              "1  15.0          8         350.0       165.0  ...          70  0.1     0.0    0.0\n",
              "2  18.0          8         318.0       150.0  ...          70  0.1     0.0    0.0\n",
              "3  16.0          8         304.0       150.0  ...          70  0.1     0.0    0.0\n",
              "4  17.0          8         302.0       140.0  ...          70  0.1     0.0    0.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9XUHvdanxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6933c125-2795-49f3-8ba7-4fe7a56c32d1"
      },
      "source": [
        "##############################################\n",
        "# 80%로 분할하기\n",
        "train_dataset = dataset.sample(frac=0.8, random_state = 0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "train_dataset\n",
        "\n",
        "\n",
        "##############################################\n",
        "# standardscale\n",
        "\n",
        "trans_stats = train_dataset.describe()\n",
        "trans_stats.pop(\"MPG\")  # label에 속하는 항목은 제거\n",
        "trans_stats = trans_stats.transpose()\n",
        "\n",
        "#############################################\n",
        "# train_dataset와 test_dataset에서 MPG항목만 labels로 옮김\n",
        "\n",
        "train_labels = train_dataset.pop(\"MPG\")\n",
        "test_labels = test_dataset.pop(\"MPG\")\n",
        "\n",
        "# train_dataset, train_labels, test_dataset, test_labels\n",
        "############################################\n",
        "# standard scale\n",
        "def norm(x):\n",
        "  return (x-trans_stats['mean']) / trans_stats['std']\n",
        "\n",
        "train_dataset = norm(train_dataset)\n",
        "train_dataset\n",
        "\n",
        "test_dataset = norm(test_dataset)\n",
        "\n",
        "#############################################\n",
        "# 모델 생성\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(64, activation=\"relu\", input_shape=[len(train_dataset.keys())]),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "###########################################\n",
        "optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "#회귀 : loss:mse로 지표(metrics)는 mae\n",
        "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"mse\"])\n",
        "\n",
        "###########################################\n",
        "#학습하기 1000\n",
        "# validation_split=0.2\n",
        "history = model.fit(train_dataset, train_labels, epochs=1000, validation_split=0.2)\n",
        "\n",
        "history.history.keys()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 336.8155 - mae: 15.6998 - mse: 336.8155 - val_loss: 280.2402 - val_mae: 15.2935 - val_mse: 280.2402\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 101.4602 - mae: 7.5340 - mse: 101.4602 - val_loss: 126.0692 - val_mae: 8.9295 - val_mse: 126.0692\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 167.0303 - mae: 9.3405 - mse: 167.0303 - val_loss: 443.4562 - val_mae: 19.7715 - val_mse: 443.4562\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 188.4191 - mae: 11.7290 - mse: 188.4191 - val_loss: 32.9337 - val_mae: 4.2740 - val_mse: 32.9337\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 63.2384 - mae: 6.0137 - mse: 63.2384 - val_loss: 37.9472 - val_mae: 4.5152 - val_mse: 37.9472\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.1760 - mae: 3.5377 - mse: 22.1760 - val_loss: 22.6124 - val_mae: 3.6415 - val_mse: 22.6124\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6849 - mae: 2.8453 - mse: 14.6849 - val_loss: 12.3746 - val_mae: 2.5928 - val_mse: 12.3746\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.3839 - mae: 3.0693 - mse: 17.3839 - val_loss: 13.0818 - val_mae: 2.7572 - val_mse: 13.0818\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.3297 - mae: 3.1500 - mse: 18.3297 - val_loss: 9.0081 - val_mae: 2.2269 - val_mse: 9.0081\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.0527 - mae: 2.2861 - mse: 10.0527 - val_loss: 15.5561 - val_mae: 3.0059 - val_mse: 15.5561\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.0537 - mae: 2.2318 - mse: 9.0537 - val_loss: 11.1652 - val_mae: 2.6574 - val_mse: 11.1652\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 16.7837 - mae: 2.9229 - mse: 16.7837 - val_loss: 14.5742 - val_mae: 2.7570 - val_mse: 14.5742\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.1172 - mae: 2.6430 - mse: 13.1172 - val_loss: 8.9571 - val_mae: 2.2589 - val_mse: 8.9571\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.8963 - mae: 2.1850 - mse: 8.8963 - val_loss: 12.3544 - val_mae: 2.7971 - val_mse: 12.3544\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 16.2825 - mae: 2.9665 - mse: 16.2825 - val_loss: 8.7669 - val_mae: 2.2791 - val_mse: 8.7669\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.2293 - mae: 2.1066 - mse: 9.2293 - val_loss: 13.9599 - val_mae: 2.9527 - val_mse: 13.9599\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.3922 - mae: 2.0448 - mse: 8.3922 - val_loss: 12.0061 - val_mae: 2.7135 - val_mse: 12.0061\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.9946 - mae: 2.7242 - mse: 13.9946 - val_loss: 10.9167 - val_mae: 2.4951 - val_mse: 10.9167\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.3208 - mae: 2.1499 - mse: 9.3208 - val_loss: 9.0710 - val_mae: 2.2524 - val_mse: 9.0710\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.1792 - mae: 2.1640 - mse: 9.1792 - val_loss: 8.4322 - val_mae: 2.2962 - val_mse: 8.4322\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0014 - mae: 1.9369 - mse: 7.0014 - val_loss: 8.6346 - val_mae: 2.2548 - val_mse: 8.6346\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.8031 - mae: 1.9512 - mse: 6.8031 - val_loss: 8.0317 - val_mae: 2.2661 - val_mse: 8.0317\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8441 - mae: 1.8656 - mse: 6.8441 - val_loss: 12.5810 - val_mae: 2.6317 - val_mse: 12.5810\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.2345 - mae: 2.6233 - mse: 13.2345 - val_loss: 8.5969 - val_mae: 2.2515 - val_mse: 8.5969\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.9125 - mae: 2.6509 - mse: 13.9125 - val_loss: 8.7246 - val_mae: 2.2082 - val_mse: 8.7246\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.1429 - mae: 2.1028 - mse: 9.1429 - val_loss: 8.1347 - val_mae: 2.2582 - val_mse: 8.1347\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.8118 - mae: 2.1713 - mse: 8.8118 - val_loss: 20.3636 - val_mae: 3.2525 - val_mse: 20.3636\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.3070 - mae: 2.1233 - mse: 9.3070 - val_loss: 9.1192 - val_mae: 2.2918 - val_mse: 9.1192\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.1169 - mae: 1.9632 - mse: 7.1169 - val_loss: 11.4035 - val_mae: 2.4940 - val_mse: 11.4035\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.0419 - mae: 1.9977 - mse: 8.0419 - val_loss: 11.0207 - val_mae: 2.6507 - val_mse: 11.0207\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7354 - mae: 2.1158 - mse: 8.7354 - val_loss: 15.4794 - val_mae: 3.0114 - val_mse: 15.4794\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.8422 - mae: 1.8908 - mse: 6.8422 - val_loss: 8.6127 - val_mae: 2.2859 - val_mse: 8.6127\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1791 - mae: 1.7872 - mse: 6.1791 - val_loss: 8.8980 - val_mae: 2.3368 - val_mse: 8.8980\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.9366 - mae: 1.8663 - mse: 6.9366 - val_loss: 14.1987 - val_mae: 2.9276 - val_mse: 14.1987\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.0273 - mae: 2.4603 - mse: 12.0273 - val_loss: 12.7862 - val_mae: 2.7585 - val_mse: 12.7862\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.6866 - mae: 2.0770 - mse: 8.6866 - val_loss: 8.2655 - val_mae: 2.2087 - val_mse: 8.2655\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8589 - mae: 1.7469 - mse: 5.8589 - val_loss: 7.7295 - val_mae: 2.1839 - val_mse: 7.7295\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1675 - mae: 1.7677 - mse: 6.1675 - val_loss: 7.9600 - val_mae: 2.2441 - val_mse: 7.9600\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.7871 - mae: 1.8216 - mse: 6.7871 - val_loss: 7.9500 - val_mae: 2.1255 - val_mse: 7.9500\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.5719 - mae: 2.0081 - mse: 7.5719 - val_loss: 10.2132 - val_mae: 2.5605 - val_mse: 10.2132\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.3154 - mae: 2.2651 - mse: 10.3154 - val_loss: 12.3701 - val_mae: 2.7151 - val_mse: 12.3701\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.9419 - mae: 1.9212 - mse: 6.9419 - val_loss: 7.9387 - val_mae: 2.2300 - val_mse: 7.9387\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.4968 - mae: 1.9096 - mse: 7.4968 - val_loss: 8.0662 - val_mae: 2.2367 - val_mse: 8.0662\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0218 - mae: 1.7403 - mse: 6.0218 - val_loss: 8.0213 - val_mae: 2.1915 - val_mse: 8.0213\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8645 - mae: 1.6723 - mse: 5.8645 - val_loss: 8.5844 - val_mae: 2.2971 - val_mse: 8.5844\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1432 - mae: 1.7298 - mse: 6.1432 - val_loss: 8.7961 - val_mae: 2.2024 - val_mse: 8.7961\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.7281 - mae: 1.8933 - mse: 7.7281 - val_loss: 7.6528 - val_mae: 2.1468 - val_mse: 7.6528\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8705 - mae: 1.6933 - mse: 5.8705 - val_loss: 7.4979 - val_mae: 2.1323 - val_mse: 7.4979\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.8224 - mae: 2.2455 - mse: 10.8224 - val_loss: 17.1770 - val_mae: 3.2082 - val_mse: 17.1770\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.8473 - mae: 2.4736 - mse: 11.8473 - val_loss: 10.7686 - val_mae: 2.5535 - val_mse: 10.7686\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0149 - mae: 1.7182 - mse: 6.0149 - val_loss: 8.4540 - val_mae: 2.2059 - val_mse: 8.4540\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5043 - mae: 1.6151 - mse: 5.5043 - val_loss: 7.7141 - val_mae: 2.1082 - val_mse: 7.7141\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6604 - mae: 1.6213 - mse: 5.6604 - val_loss: 8.9430 - val_mae: 2.2056 - val_mse: 8.9430\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.6673 - mae: 1.7941 - mse: 6.6673 - val_loss: 8.5074 - val_mae: 2.1660 - val_mse: 8.5074\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.0198 - mae: 2.1154 - mse: 10.0198 - val_loss: 9.5157 - val_mae: 2.2967 - val_mse: 9.5157\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4284 - mae: 1.7281 - mse: 6.4284 - val_loss: 8.4201 - val_mae: 2.1994 - val_mse: 8.4201\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.2640 - mae: 2.1291 - mse: 9.2640 - val_loss: 9.3348 - val_mae: 2.2429 - val_mse: 9.3348\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.8865 - mae: 1.9327 - mse: 6.8865 - val_loss: 10.1018 - val_mae: 2.4804 - val_mse: 10.1018\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.7004 - mae: 1.7868 - mse: 6.7004 - val_loss: 7.9882 - val_mae: 2.1568 - val_mse: 7.9882\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0966 - mae: 1.7645 - mse: 6.0966 - val_loss: 8.5156 - val_mae: 2.2374 - val_mse: 8.5156\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4233 - mae: 1.7804 - mse: 6.4233 - val_loss: 8.5733 - val_mae: 2.2456 - val_mse: 8.5733\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.9166 - mae: 1.6941 - mse: 5.9166 - val_loss: 14.2452 - val_mae: 2.7622 - val_mse: 14.2452\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.6530 - mae: 2.0399 - mse: 8.6530 - val_loss: 8.8177 - val_mae: 2.3316 - val_mse: 8.8177\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6369 - mae: 1.6399 - mse: 5.6369 - val_loss: 8.2356 - val_mae: 2.1330 - val_mse: 8.2356\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.4715 - mae: 1.8936 - mse: 7.4715 - val_loss: 7.6006 - val_mae: 2.0654 - val_mse: 7.6006\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.3864 - mae: 1.9845 - mse: 8.3864 - val_loss: 9.6906 - val_mae: 2.3977 - val_mse: 9.6906\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0897 - mae: 1.7298 - mse: 6.0897 - val_loss: 11.3761 - val_mae: 2.4901 - val_mse: 11.3761\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1356 - mae: 1.7807 - mse: 6.1356 - val_loss: 8.7720 - val_mae: 2.3427 - val_mse: 8.7720\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1753 - mae: 1.6431 - mse: 6.1753 - val_loss: 10.4260 - val_mae: 2.4678 - val_mse: 10.4260\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6925 - mae: 1.6527 - mse: 5.6925 - val_loss: 7.7864 - val_mae: 2.1339 - val_mse: 7.7864\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3238 - mae: 1.5988 - mse: 5.3238 - val_loss: 8.3663 - val_mae: 2.1730 - val_mse: 8.3663\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5519 - mae: 1.6018 - mse: 5.5519 - val_loss: 8.0820 - val_mae: 2.1960 - val_mse: 8.0820\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6462 - mae: 1.6845 - mse: 5.6462 - val_loss: 12.1626 - val_mae: 2.6284 - val_mse: 12.1626\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0637 - mae: 1.7184 - mse: 6.0637 - val_loss: 8.8321 - val_mae: 2.3184 - val_mse: 8.8321\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.0862 - mae: 1.6949 - mse: 6.0862 - val_loss: 11.0384 - val_mae: 2.6831 - val_mse: 11.0384\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.7663 - mae: 1.9628 - mse: 7.7663 - val_loss: 8.5813 - val_mae: 2.1663 - val_mse: 8.5813\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2642 - mae: 1.5809 - mse: 5.2642 - val_loss: 9.0664 - val_mae: 2.2962 - val_mse: 9.0664\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2753 - mae: 1.6416 - mse: 5.2753 - val_loss: 9.2764 - val_mae: 2.2740 - val_mse: 9.2764\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3693 - mae: 1.6254 - mse: 5.3693 - val_loss: 8.2267 - val_mae: 2.1350 - val_mse: 8.2267\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2177 - mae: 1.6129 - mse: 5.2177 - val_loss: 9.8039 - val_mae: 2.3300 - val_mse: 9.8039\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.1117 - mae: 1.8322 - mse: 7.1117 - val_loss: 8.8150 - val_mae: 2.2749 - val_mse: 8.8150\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2711 - mae: 1.7660 - mse: 6.2711 - val_loss: 9.1075 - val_mae: 2.2294 - val_mse: 9.1075\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6372 - mae: 1.6221 - mse: 5.6372 - val_loss: 8.1588 - val_mae: 2.1310 - val_mse: 8.1588\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.3488 - mae: 1.7677 - mse: 6.3488 - val_loss: 8.3581 - val_mae: 2.1926 - val_mse: 8.3581\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7726 - mae: 1.5835 - mse: 5.7726 - val_loss: 10.6964 - val_mae: 2.4176 - val_mse: 10.6964\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.1061 - mae: 1.8176 - mse: 7.1061 - val_loss: 12.1318 - val_mae: 2.7105 - val_mse: 12.1318\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.5549 - mae: 1.6555 - mse: 5.5549 - val_loss: 10.6076 - val_mae: 2.5020 - val_mse: 10.6076\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.6808 - mae: 1.8592 - mse: 6.6808 - val_loss: 8.7193 - val_mae: 2.2011 - val_mse: 8.7193\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1085 - mae: 1.7921 - mse: 6.1085 - val_loss: 15.1602 - val_mae: 2.8307 - val_mse: 15.1602\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.6941 - mae: 2.1994 - mse: 10.6941 - val_loss: 11.8680 - val_mae: 2.6789 - val_mse: 11.8680\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7786 - mae: 1.7079 - mse: 5.7786 - val_loss: 8.1869 - val_mae: 2.2607 - val_mse: 8.1869\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.0064 - mae: 1.8649 - mse: 7.0064 - val_loss: 8.9539 - val_mae: 2.2206 - val_mse: 8.9539\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.3996 - mae: 1.7505 - mse: 6.3996 - val_loss: 7.7476 - val_mae: 1.9994 - val_mse: 7.7476\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8789 - mae: 1.8373 - mse: 6.8789 - val_loss: 8.0179 - val_mae: 2.2143 - val_mse: 8.0179\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4895 - mae: 1.6218 - mse: 5.4895 - val_loss: 10.1028 - val_mae: 2.3565 - val_mse: 10.1028\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2680 - mae: 1.5457 - mse: 5.2680 - val_loss: 7.7220 - val_mae: 2.0818 - val_mse: 7.7220\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7113 - mae: 1.5270 - mse: 4.7113 - val_loss: 7.4882 - val_mae: 2.0312 - val_mse: 7.4882\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9599 - mae: 1.4966 - mse: 4.9599 - val_loss: 10.0106 - val_mae: 2.3440 - val_mse: 10.0106\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6326 - mae: 1.7197 - mse: 5.6326 - val_loss: 8.6040 - val_mae: 2.1632 - val_mse: 8.6040\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8429 - mae: 1.7068 - mse: 5.8429 - val_loss: 7.9430 - val_mae: 2.1054 - val_mse: 7.9430\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.5190 - mae: 1.6936 - mse: 5.5190 - val_loss: 7.5868 - val_mae: 2.0746 - val_mse: 7.5868\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7291 - mae: 1.4767 - mse: 4.7291 - val_loss: 7.4769 - val_mae: 2.0248 - val_mse: 7.4769\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4842 - mae: 1.7079 - mse: 5.4842 - val_loss: 7.3007 - val_mae: 2.0429 - val_mse: 7.3007\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2776 - mae: 1.8590 - mse: 7.2776 - val_loss: 8.6196 - val_mae: 2.1737 - val_mse: 8.6196\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.2515 - mae: 1.8271 - mse: 7.2515 - val_loss: 17.0506 - val_mae: 3.3149 - val_mse: 17.0506\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8753 - mae: 1.7115 - mse: 5.8753 - val_loss: 8.4323 - val_mae: 2.2483 - val_mse: 8.4323\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9116 - mae: 1.5362 - mse: 4.9116 - val_loss: 10.9393 - val_mae: 2.5099 - val_mse: 10.9393\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0022 - mae: 1.5832 - mse: 5.0022 - val_loss: 8.2339 - val_mae: 2.1701 - val_mse: 8.2339\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8618 - mae: 1.5393 - mse: 4.8618 - val_loss: 9.1542 - val_mae: 2.3630 - val_mse: 9.1542\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9407 - mae: 1.5281 - mse: 4.9407 - val_loss: 8.8009 - val_mae: 2.2126 - val_mse: 8.8009\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8677 - mae: 1.4753 - mse: 4.8677 - val_loss: 10.2563 - val_mae: 2.3830 - val_mse: 10.2563\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8752 - mae: 1.5565 - mse: 4.8752 - val_loss: 8.4290 - val_mae: 2.2323 - val_mse: 8.4290\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9347 - mae: 1.5017 - mse: 4.9347 - val_loss: 8.8630 - val_mae: 2.2231 - val_mse: 8.8630\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8904 - mae: 1.5086 - mse: 4.8904 - val_loss: 7.7770 - val_mae: 2.0808 - val_mse: 7.7770\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.9022 - mae: 2.3299 - mse: 10.9022 - val_loss: 9.0629 - val_mae: 2.1783 - val_mse: 9.0629\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1959 - mae: 1.6065 - mse: 5.1959 - val_loss: 18.1372 - val_mae: 3.1842 - val_mse: 18.1372\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.6631 - mae: 1.8939 - mse: 8.6631 - val_loss: 8.0777 - val_mae: 2.0917 - val_mse: 8.0777\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9819 - mae: 1.5782 - mse: 4.9819 - val_loss: 7.4190 - val_mae: 2.0582 - val_mse: 7.4190\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1000 - mae: 1.6751 - mse: 6.1000 - val_loss: 8.1368 - val_mae: 2.1598 - val_mse: 8.1368\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5296 - mae: 1.4606 - mse: 4.5296 - val_loss: 7.4159 - val_mae: 2.0425 - val_mse: 7.4159\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1288 - mae: 1.5143 - mse: 5.1288 - val_loss: 7.2276 - val_mae: 2.0084 - val_mse: 7.2276\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4594 - mae: 1.5988 - mse: 5.4594 - val_loss: 7.2929 - val_mae: 1.9441 - val_mse: 7.2929\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.7412 - mae: 1.8496 - mse: 6.7412 - val_loss: 9.1144 - val_mae: 2.3040 - val_mse: 9.1144\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9192 - mae: 1.5570 - mse: 4.9192 - val_loss: 8.8086 - val_mae: 2.1768 - val_mse: 8.8086\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9302 - mae: 1.6154 - mse: 4.9302 - val_loss: 7.5892 - val_mae: 2.0686 - val_mse: 7.5892\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6256 - mae: 1.5046 - mse: 4.6256 - val_loss: 7.5643 - val_mae: 2.0482 - val_mse: 7.5643\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8116 - mae: 1.5381 - mse: 4.8116 - val_loss: 8.5474 - val_mae: 2.2021 - val_mse: 8.5474\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6472 - mae: 1.5367 - mse: 4.6472 - val_loss: 8.3441 - val_mae: 2.1035 - val_mse: 8.3441\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5055 - mae: 1.5349 - mse: 4.5055 - val_loss: 8.6220 - val_mae: 2.2496 - val_mse: 8.6220\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8541 - mae: 1.6630 - mse: 5.8541 - val_loss: 8.6312 - val_mae: 2.1807 - val_mse: 8.6312\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3047 - mae: 1.5925 - mse: 5.3047 - val_loss: 8.2720 - val_mae: 2.1150 - val_mse: 8.2720\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1693 - mae: 1.5756 - mse: 5.1693 - val_loss: 8.8810 - val_mae: 2.2498 - val_mse: 8.8810\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7846 - mae: 1.5077 - mse: 4.7846 - val_loss: 7.4203 - val_mae: 2.0945 - val_mse: 7.4203\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5246 - mae: 1.4318 - mse: 4.5246 - val_loss: 8.8872 - val_mae: 2.2590 - val_mse: 8.8872\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6439 - mae: 1.4640 - mse: 4.6439 - val_loss: 7.6364 - val_mae: 2.0739 - val_mse: 7.6364\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8433 - mae: 1.5193 - mse: 4.8433 - val_loss: 13.5333 - val_mae: 2.8126 - val_mse: 13.5333\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5639 - mae: 1.5229 - mse: 4.5639 - val_loss: 7.5482 - val_mae: 2.0012 - val_mse: 7.5482\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4447 - mae: 1.7208 - mse: 6.4447 - val_loss: 10.4416 - val_mae: 2.3605 - val_mse: 10.4416\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8678 - mae: 1.5670 - mse: 4.8678 - val_loss: 9.7878 - val_mae: 2.3687 - val_mse: 9.7878\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5956 - mae: 1.5272 - mse: 4.5956 - val_loss: 10.2266 - val_mae: 2.4169 - val_mse: 10.2266\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4174 - mae: 1.4779 - mse: 4.4174 - val_loss: 8.4651 - val_mae: 2.1302 - val_mse: 8.4651\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8386 - mae: 1.7013 - mse: 5.8386 - val_loss: 10.2492 - val_mae: 2.5131 - val_mse: 10.2492\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5992 - mae: 1.4786 - mse: 4.5992 - val_loss: 10.4507 - val_mae: 2.4845 - val_mse: 10.4507\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7686 - mae: 1.4807 - mse: 4.7686 - val_loss: 7.9641 - val_mae: 2.1507 - val_mse: 7.9641\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0712 - mae: 1.4055 - mse: 4.0712 - val_loss: 8.3069 - val_mae: 2.2078 - val_mse: 8.3069\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1704 - mae: 1.3964 - mse: 4.1704 - val_loss: 7.4861 - val_mae: 2.0122 - val_mse: 7.4861\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0041 - mae: 1.5623 - mse: 5.0041 - val_loss: 9.1601 - val_mae: 2.3208 - val_mse: 9.1601\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1284 - mae: 1.4283 - mse: 4.1284 - val_loss: 10.4763 - val_mae: 2.5313 - val_mse: 10.4763\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5453 - mae: 1.4791 - mse: 4.5453 - val_loss: 8.7527 - val_mae: 2.2149 - val_mse: 8.7527\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3738 - mae: 1.6392 - mse: 5.3738 - val_loss: 7.1943 - val_mae: 2.0441 - val_mse: 7.1943\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1877 - mae: 1.3993 - mse: 4.1877 - val_loss: 7.7821 - val_mae: 2.1110 - val_mse: 7.7821\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2263 - mae: 1.6540 - mse: 5.2263 - val_loss: 6.9078 - val_mae: 1.9204 - val_mse: 6.9078\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6787 - mae: 1.5269 - mse: 4.6787 - val_loss: 7.6126 - val_mae: 2.0141 - val_mse: 7.6126\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.1133 - mae: 1.8855 - mse: 7.1133 - val_loss: 8.8066 - val_mae: 2.2865 - val_mse: 8.8066\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4823 - mae: 1.5129 - mse: 4.4823 - val_loss: 8.8156 - val_mae: 2.2407 - val_mse: 8.8156\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9826 - mae: 1.5710 - mse: 4.9826 - val_loss: 7.3533 - val_mae: 1.9883 - val_mse: 7.3533\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5907 - mae: 1.4698 - mse: 4.5907 - val_loss: 9.5263 - val_mae: 2.2381 - val_mse: 9.5263\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5195 - mae: 1.4888 - mse: 4.5195 - val_loss: 9.1003 - val_mae: 2.2943 - val_mse: 9.1003\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6625 - mae: 1.6903 - mse: 5.6625 - val_loss: 7.5610 - val_mae: 2.0215 - val_mse: 7.5610\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4082 - mae: 1.4325 - mse: 4.4082 - val_loss: 8.7076 - val_mae: 2.1476 - val_mse: 8.7076\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5591 - mae: 1.5221 - mse: 4.5591 - val_loss: 10.5263 - val_mae: 2.5519 - val_mse: 10.5263\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9866 - mae: 1.3718 - mse: 3.9866 - val_loss: 8.3687 - val_mae: 2.1856 - val_mse: 8.3687\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4352 - mae: 1.6935 - mse: 5.4352 - val_loss: 8.4813 - val_mae: 2.2253 - val_mse: 8.4813\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3141 - mae: 1.4269 - mse: 4.3141 - val_loss: 8.8259 - val_mae: 2.3018 - val_mse: 8.8259\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0238 - mae: 1.4033 - mse: 4.0238 - val_loss: 7.6847 - val_mae: 2.0863 - val_mse: 7.6847\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2551 - mae: 1.4241 - mse: 4.2551 - val_loss: 10.8198 - val_mae: 2.4629 - val_mse: 10.8198\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.8391 - mae: 1.7040 - mse: 5.8391 - val_loss: 12.3885 - val_mae: 2.6931 - val_mse: 12.3885\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7401 - mae: 1.6106 - mse: 4.7401 - val_loss: 7.8369 - val_mae: 2.0388 - val_mse: 7.8369\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5219 - mae: 1.4868 - mse: 4.5219 - val_loss: 9.8841 - val_mae: 2.3530 - val_mse: 9.8841\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3584 - mae: 1.4325 - mse: 4.3584 - val_loss: 7.9406 - val_mae: 2.0729 - val_mse: 7.9406\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5852 - mae: 1.4582 - mse: 4.5852 - val_loss: 11.5795 - val_mae: 2.4847 - val_mse: 11.5795\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4268 - mae: 1.4498 - mse: 4.4268 - val_loss: 9.4819 - val_mae: 2.2472 - val_mse: 9.4819\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2180 - mae: 1.7221 - mse: 6.2180 - val_loss: 7.9776 - val_mae: 2.1010 - val_mse: 7.9776\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4236 - mae: 1.5609 - mse: 5.4236 - val_loss: 7.8300 - val_mae: 1.9775 - val_mse: 7.8300\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8398 - mae: 1.3354 - mse: 3.8398 - val_loss: 8.7452 - val_mae: 2.1523 - val_mse: 8.7452\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1144 - mae: 1.4237 - mse: 4.1144 - val_loss: 8.5784 - val_mae: 2.1819 - val_mse: 8.5784\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7161 - mae: 1.5860 - mse: 4.7161 - val_loss: 7.8668 - val_mae: 2.0289 - val_mse: 7.8668\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9573 - mae: 1.3785 - mse: 3.9573 - val_loss: 8.5466 - val_mae: 2.2111 - val_mse: 8.5466\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2103 - mae: 1.7592 - mse: 6.2103 - val_loss: 7.0427 - val_mae: 1.9186 - val_mse: 7.0427\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2221 - mae: 1.4748 - mse: 4.2221 - val_loss: 10.0324 - val_mae: 2.4064 - val_mse: 10.0324\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0044 - mae: 1.3815 - mse: 4.0044 - val_loss: 8.0604 - val_mae: 2.1348 - val_mse: 8.0604\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8440 - mae: 1.3011 - mse: 3.8440 - val_loss: 15.6145 - val_mae: 2.8215 - val_mse: 15.6145\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4009 - mae: 1.7227 - mse: 6.4009 - val_loss: 7.6901 - val_mae: 2.0464 - val_mse: 7.6901\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2192 - mae: 1.4395 - mse: 4.2192 - val_loss: 8.4340 - val_mae: 2.1903 - val_mse: 8.4340\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.0831 - mae: 1.4420 - mse: 4.0831 - val_loss: 10.2171 - val_mae: 2.3662 - val_mse: 10.2171\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3783 - mae: 1.4870 - mse: 4.3783 - val_loss: 8.9787 - val_mae: 2.2339 - val_mse: 8.9787\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.3761 - mae: 1.6593 - mse: 6.3761 - val_loss: 5.8348 - val_mae: 1.7810 - val_mse: 5.8348\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0994 - mae: 1.4418 - mse: 4.0994 - val_loss: 8.1758 - val_mae: 2.1477 - val_mse: 8.1758\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6550 - mae: 1.2744 - mse: 3.6550 - val_loss: 8.5590 - val_mae: 2.1803 - val_mse: 8.5590\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0522 - mae: 1.3919 - mse: 4.0522 - val_loss: 12.8467 - val_mae: 2.7387 - val_mse: 12.8467\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7467 - mae: 1.4022 - mse: 3.7467 - val_loss: 8.3129 - val_mae: 2.1598 - val_mse: 8.3129\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2501 - mae: 1.5848 - mse: 5.2501 - val_loss: 8.0274 - val_mae: 2.1408 - val_mse: 8.0274\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1214 - mae: 1.4232 - mse: 4.1214 - val_loss: 9.1146 - val_mae: 2.3135 - val_mse: 9.1146\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8500 - mae: 1.3224 - mse: 3.8500 - val_loss: 9.0572 - val_mae: 2.2395 - val_mse: 9.0572\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3418 - mae: 1.4600 - mse: 4.3418 - val_loss: 8.4644 - val_mae: 2.1984 - val_mse: 8.4644\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8169 - mae: 1.3421 - mse: 3.8169 - val_loss: 7.7498 - val_mae: 2.0925 - val_mse: 7.7498\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7102 - mae: 1.3181 - mse: 3.7102 - val_loss: 6.9196 - val_mae: 1.9584 - val_mse: 6.9196\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6965 - mae: 1.3946 - mse: 4.6965 - val_loss: 16.9467 - val_mae: 3.0935 - val_mse: 16.9467\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.4636 - mae: 2.0985 - mse: 8.4636 - val_loss: 8.6461 - val_mae: 2.2903 - val_mse: 8.6461\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7690 - mae: 1.3480 - mse: 3.7690 - val_loss: 9.9537 - val_mae: 2.3749 - val_mse: 9.9537\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6178 - mae: 1.2760 - mse: 3.6178 - val_loss: 6.6215 - val_mae: 1.8851 - val_mse: 6.6215\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2782 - mae: 1.3927 - mse: 4.2782 - val_loss: 8.4088 - val_mae: 2.2019 - val_mse: 8.4088\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.0007 - mae: 1.4009 - mse: 4.0007 - val_loss: 8.5470 - val_mae: 2.2072 - val_mse: 8.5470\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4178 - mae: 1.8361 - mse: 6.4178 - val_loss: 8.7225 - val_mae: 2.2880 - val_mse: 8.7225\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7008 - mae: 1.5754 - mse: 4.7008 - val_loss: 7.5466 - val_mae: 2.0113 - val_mse: 7.5466\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6214 - mae: 1.4381 - mse: 4.6214 - val_loss: 7.5431 - val_mae: 2.0851 - val_mse: 7.5431\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3368 - mae: 1.4956 - mse: 4.3368 - val_loss: 8.2059 - val_mae: 2.1457 - val_mse: 8.2059\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0778 - mae: 1.3703 - mse: 4.0778 - val_loss: 7.1876 - val_mae: 2.0107 - val_mse: 7.1876\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8181 - mae: 1.5255 - mse: 4.8181 - val_loss: 10.2706 - val_mae: 2.4683 - val_mse: 10.2706\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.0657 - mae: 1.4093 - mse: 4.0657 - val_loss: 7.1601 - val_mae: 1.9700 - val_mse: 7.1601\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2528 - mae: 1.4774 - mse: 4.2528 - val_loss: 8.0563 - val_mae: 2.1277 - val_mse: 8.0563\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7343 - mae: 1.5682 - mse: 4.7343 - val_loss: 9.1170 - val_mae: 2.2641 - val_mse: 9.1170\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.4261 - mae: 1.7309 - mse: 5.4261 - val_loss: 8.6476 - val_mae: 2.2958 - val_mse: 8.6476\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7190 - mae: 1.5450 - mse: 4.7190 - val_loss: 7.3257 - val_mae: 2.0148 - val_mse: 7.3257\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6145 - mae: 1.3210 - mse: 3.6145 - val_loss: 7.1849 - val_mae: 2.0426 - val_mse: 7.1849\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5318 - mae: 1.5383 - mse: 4.5318 - val_loss: 8.2269 - val_mae: 2.1558 - val_mse: 8.2269\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0849 - mae: 1.3828 - mse: 4.0849 - val_loss: 7.3325 - val_mae: 2.0259 - val_mse: 7.3325\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6957 - mae: 1.3713 - mse: 3.6957 - val_loss: 8.4303 - val_mae: 2.1272 - val_mse: 8.4303\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5654 - mae: 1.2958 - mse: 3.5654 - val_loss: 9.2672 - val_mae: 2.3335 - val_mse: 9.2672\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6377 - mae: 1.3097 - mse: 3.6377 - val_loss: 8.1398 - val_mae: 2.1757 - val_mse: 8.1398\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1252 - mae: 1.4583 - mse: 4.1252 - val_loss: 11.3251 - val_mae: 2.4653 - val_mse: 11.3251\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1349 - mae: 1.4071 - mse: 4.1349 - val_loss: 11.0488 - val_mae: 2.4993 - val_mse: 11.0488\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6355 - mae: 1.2769 - mse: 3.6355 - val_loss: 7.2800 - val_mae: 2.0100 - val_mse: 7.2800\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3221 - mae: 1.4574 - mse: 4.3221 - val_loss: 11.0817 - val_mae: 2.5421 - val_mse: 11.0817\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9678 - mae: 1.3691 - mse: 3.9678 - val_loss: 8.1181 - val_mae: 2.1384 - val_mse: 8.1181\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8129 - mae: 1.4520 - mse: 4.8129 - val_loss: 16.5261 - val_mae: 3.2132 - val_mse: 16.5261\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1888 - mae: 1.4162 - mse: 4.1888 - val_loss: 8.1512 - val_mae: 2.1102 - val_mse: 8.1512\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2183 - mae: 1.3061 - mse: 3.2183 - val_loss: 8.0121 - val_mae: 2.1246 - val_mse: 8.0121\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4829 - mae: 1.2840 - mse: 3.4829 - val_loss: 8.8565 - val_mae: 2.2318 - val_mse: 8.8565\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2001 - mae: 1.2950 - mse: 3.2001 - val_loss: 7.8647 - val_mae: 2.2444 - val_mse: 7.8647\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7555 - mae: 1.2882 - mse: 3.7555 - val_loss: 11.4206 - val_mae: 2.5529 - val_mse: 11.4206\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.9433 - mae: 1.6731 - mse: 5.9433 - val_loss: 8.9763 - val_mae: 2.1998 - val_mse: 8.9763\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8941 - mae: 1.3868 - mse: 3.8941 - val_loss: 7.3960 - val_mae: 2.0132 - val_mse: 7.3960\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1497 - mae: 1.6683 - mse: 6.1497 - val_loss: 9.4413 - val_mae: 2.2420 - val_mse: 9.4413\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8137 - mae: 1.3229 - mse: 3.8137 - val_loss: 11.0110 - val_mae: 2.3781 - val_mse: 11.0110\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.5617 - mae: 1.5322 - mse: 4.5617 - val_loss: 8.6193 - val_mae: 2.2026 - val_mse: 8.6193\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8289 - mae: 1.3540 - mse: 3.8289 - val_loss: 9.3151 - val_mae: 2.2861 - val_mse: 9.3151\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6358 - mae: 1.3270 - mse: 3.6358 - val_loss: 9.3621 - val_mae: 2.3270 - val_mse: 9.3621\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3721 - mae: 1.2995 - mse: 3.3721 - val_loss: 13.9935 - val_mae: 2.6817 - val_mse: 13.9935\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8417 - mae: 1.7183 - mse: 5.8417 - val_loss: 7.8356 - val_mae: 2.1393 - val_mse: 7.8356\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0412 - mae: 1.3936 - mse: 4.0412 - val_loss: 11.1986 - val_mae: 2.4890 - val_mse: 11.1986\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4357 - mae: 1.5402 - mse: 4.4357 - val_loss: 8.2216 - val_mae: 2.1160 - val_mse: 8.2216\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6300 - mae: 1.2673 - mse: 3.6300 - val_loss: 9.1823 - val_mae: 2.2718 - val_mse: 9.1823\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3776 - mae: 1.6342 - mse: 5.3776 - val_loss: 8.2556 - val_mae: 2.2021 - val_mse: 8.2556\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1316 - mae: 1.5930 - mse: 5.1316 - val_loss: 9.5944 - val_mae: 2.2785 - val_mse: 9.5944\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6982 - mae: 1.3077 - mse: 3.6982 - val_loss: 12.8343 - val_mae: 2.6768 - val_mse: 12.8343\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4707 - mae: 1.4487 - mse: 4.4707 - val_loss: 8.0553 - val_mae: 2.1607 - val_mse: 8.0553\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3719 - mae: 1.3784 - mse: 4.3719 - val_loss: 7.6627 - val_mae: 2.0950 - val_mse: 7.6627\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2699 - mae: 1.1846 - mse: 3.2699 - val_loss: 8.2243 - val_mae: 2.1617 - val_mse: 8.2243\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7041 - mae: 1.3860 - mse: 3.7041 - val_loss: 7.8027 - val_mae: 2.1340 - val_mse: 7.8027\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4764 - mae: 1.3296 - mse: 3.4764 - val_loss: 7.2540 - val_mae: 1.9957 - val_mse: 7.2540\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4517 - mae: 1.2649 - mse: 3.4517 - val_loss: 7.3299 - val_mae: 2.0319 - val_mse: 7.3299\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9157 - mae: 1.1784 - mse: 2.9157 - val_loss: 11.4696 - val_mae: 2.6311 - val_mse: 11.4696\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2419 - mae: 1.2497 - mse: 3.2419 - val_loss: 8.3829 - val_mae: 2.2104 - val_mse: 8.3829\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7871 - mae: 1.3013 - mse: 3.7871 - val_loss: 9.2039 - val_mae: 2.3398 - val_mse: 9.2039\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3143 - mae: 1.1934 - mse: 3.3143 - val_loss: 8.1453 - val_mae: 2.2162 - val_mse: 8.1453\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4065 - mae: 1.2738 - mse: 3.4065 - val_loss: 10.8055 - val_mae: 2.5004 - val_mse: 10.8055\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8793 - mae: 1.2928 - mse: 3.8793 - val_loss: 7.6532 - val_mae: 2.0430 - val_mse: 7.6532\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.1203 - mae: 1.2088 - mse: 3.1203 - val_loss: 8.5860 - val_mae: 2.2344 - val_mse: 8.5860\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.2092 - mae: 1.5589 - mse: 5.2092 - val_loss: 15.1164 - val_mae: 3.0670 - val_mse: 15.1164\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1883 - mae: 1.8833 - mse: 6.1883 - val_loss: 14.4249 - val_mae: 2.8869 - val_mse: 14.4249\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7812 - mae: 1.3148 - mse: 3.7812 - val_loss: 7.8335 - val_mae: 2.1630 - val_mse: 7.8335\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8486 - mae: 1.3606 - mse: 3.8486 - val_loss: 8.3524 - val_mae: 2.2064 - val_mse: 8.3524\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1296 - mae: 1.3471 - mse: 4.1296 - val_loss: 11.2240 - val_mae: 2.4603 - val_mse: 11.2240\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2449 - mae: 1.4590 - mse: 4.2449 - val_loss: 9.7178 - val_mae: 2.3459 - val_mse: 9.7178\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8281 - mae: 1.2875 - mse: 3.8281 - val_loss: 18.4695 - val_mae: 3.4163 - val_mse: 18.4695\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7706 - mae: 1.3373 - mse: 3.7706 - val_loss: 8.0485 - val_mae: 2.1389 - val_mse: 8.0485\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9450 - mae: 1.1821 - mse: 2.9450 - val_loss: 9.0663 - val_mae: 2.2918 - val_mse: 9.0663\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5641 - mae: 1.2835 - mse: 3.5641 - val_loss: 7.7740 - val_mae: 2.1285 - val_mse: 7.7740\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4643 - mae: 1.2069 - mse: 3.4643 - val_loss: 8.6847 - val_mae: 2.2679 - val_mse: 8.6847\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9308 - mae: 1.4446 - mse: 3.9308 - val_loss: 7.3936 - val_mae: 2.1228 - val_mse: 7.3936\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2801 - mae: 1.2534 - mse: 3.2801 - val_loss: 8.5607 - val_mae: 2.2198 - val_mse: 8.5607\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5789 - mae: 1.2764 - mse: 3.5789 - val_loss: 8.3194 - val_mae: 2.1671 - val_mse: 8.3194\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6975 - mae: 1.3500 - mse: 3.6975 - val_loss: 9.6535 - val_mae: 2.4023 - val_mse: 9.6535\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7963 - mae: 1.3516 - mse: 3.7963 - val_loss: 8.3976 - val_mae: 2.2131 - val_mse: 8.3976\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7362 - mae: 1.5091 - mse: 4.7362 - val_loss: 7.3025 - val_mae: 2.0797 - val_mse: 7.3025\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.1875 - mae: 1.2227 - mse: 3.1875 - val_loss: 7.5117 - val_mae: 2.0659 - val_mse: 7.5117\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0968 - mae: 1.4851 - mse: 4.0968 - val_loss: 12.0055 - val_mae: 2.5830 - val_mse: 12.0055\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4093 - mae: 1.5421 - mse: 4.4093 - val_loss: 7.9498 - val_mae: 2.1475 - val_mse: 7.9498\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6845 - mae: 1.3615 - mse: 3.6845 - val_loss: 8.2234 - val_mae: 2.2071 - val_mse: 8.2234\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5450 - mae: 1.2733 - mse: 3.5450 - val_loss: 10.2647 - val_mae: 2.4539 - val_mse: 10.2647\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1741 - mae: 1.2273 - mse: 3.1741 - val_loss: 8.2439 - val_mae: 2.1651 - val_mse: 8.2439\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0059 - mae: 1.1621 - mse: 3.0059 - val_loss: 9.2527 - val_mae: 2.3366 - val_mse: 9.2527\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0711 - mae: 1.1839 - mse: 3.0711 - val_loss: 8.6050 - val_mae: 2.2298 - val_mse: 8.6050\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2599 - mae: 1.2683 - mse: 3.2599 - val_loss: 8.9776 - val_mae: 2.3132 - val_mse: 8.9776\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0409 - mae: 1.2190 - mse: 3.0409 - val_loss: 10.0796 - val_mae: 2.4434 - val_mse: 10.0796\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5608 - mae: 1.3288 - mse: 3.5608 - val_loss: 8.0746 - val_mae: 2.1656 - val_mse: 8.0746\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1251 - mae: 1.2324 - mse: 3.1251 - val_loss: 8.7068 - val_mae: 2.2683 - val_mse: 8.7068\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2770 - mae: 1.2849 - mse: 3.2770 - val_loss: 9.6642 - val_mae: 2.3180 - val_mse: 9.6642\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2884 - mae: 1.2257 - mse: 3.2884 - val_loss: 8.9122 - val_mae: 2.1798 - val_mse: 8.9122\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4826 - mae: 1.3189 - mse: 3.4826 - val_loss: 9.1630 - val_mae: 2.3010 - val_mse: 9.1630\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.0785 - mae: 1.1795 - mse: 3.0785 - val_loss: 8.9029 - val_mae: 2.2966 - val_mse: 8.9029\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2048 - mae: 1.3943 - mse: 4.2048 - val_loss: 11.8747 - val_mae: 2.5973 - val_mse: 11.8747\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7894 - mae: 1.4175 - mse: 3.7894 - val_loss: 7.8148 - val_mae: 2.1095 - val_mse: 7.8148\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2461 - mae: 1.4558 - mse: 4.2461 - val_loss: 8.6097 - val_mae: 2.2484 - val_mse: 8.6097\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3455 - mae: 1.2807 - mse: 3.3455 - val_loss: 9.6763 - val_mae: 2.3945 - val_mse: 9.6763\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2345 - mae: 1.4452 - mse: 4.2345 - val_loss: 8.9208 - val_mae: 2.3162 - val_mse: 8.9208\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6242 - mae: 1.2851 - mse: 3.6242 - val_loss: 8.7499 - val_mae: 2.3080 - val_mse: 8.7499\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8450 - mae: 1.3741 - mse: 3.8450 - val_loss: 8.6805 - val_mae: 2.1800 - val_mse: 8.6805\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3145 - mae: 1.2876 - mse: 3.3145 - val_loss: 8.4674 - val_mae: 2.2693 - val_mse: 8.4674\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7173 - mae: 1.3391 - mse: 3.7173 - val_loss: 8.3931 - val_mae: 2.2536 - val_mse: 8.3931\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9922 - mae: 1.2024 - mse: 2.9922 - val_loss: 8.9438 - val_mae: 2.3537 - val_mse: 8.9438\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4652 - mae: 1.1995 - mse: 3.4652 - val_loss: 9.0333 - val_mae: 2.2471 - val_mse: 9.0333\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6188 - mae: 1.3011 - mse: 3.6188 - val_loss: 9.1197 - val_mae: 2.3148 - val_mse: 9.1197\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1221 - mae: 1.2167 - mse: 3.1221 - val_loss: 8.1039 - val_mae: 2.1753 - val_mse: 8.1039\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8066 - mae: 1.4087 - mse: 3.8066 - val_loss: 8.0962 - val_mae: 2.2051 - val_mse: 8.0962\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1007 - mae: 1.2100 - mse: 3.1007 - val_loss: 7.6206 - val_mae: 2.1256 - val_mse: 7.6206\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9503 - mae: 1.1443 - mse: 2.9503 - val_loss: 7.9863 - val_mae: 2.2149 - val_mse: 7.9863\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8167 - mae: 1.2730 - mse: 3.8167 - val_loss: 6.9391 - val_mae: 2.0396 - val_mse: 6.9391\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4900 - mae: 1.5563 - mse: 4.4900 - val_loss: 8.0059 - val_mae: 2.1820 - val_mse: 8.0059\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.2286 - mae: 1.1976 - mse: 3.2286 - val_loss: 9.3155 - val_mae: 2.3427 - val_mse: 9.3155\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4529 - mae: 1.2854 - mse: 3.4529 - val_loss: 7.2223 - val_mae: 1.9933 - val_mse: 7.2223\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2168 - mae: 1.2529 - mse: 3.2168 - val_loss: 8.1413 - val_mae: 2.2194 - val_mse: 8.1413\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8452 - mae: 1.1432 - mse: 2.8452 - val_loss: 8.5387 - val_mae: 2.1549 - val_mse: 8.5387\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6538 - mae: 1.2839 - mse: 3.6538 - val_loss: 9.3058 - val_mae: 2.1915 - val_mse: 9.3058\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2054 - mae: 1.2542 - mse: 3.2054 - val_loss: 7.5964 - val_mae: 2.1442 - val_mse: 7.5964\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5793 - mae: 1.3572 - mse: 3.5793 - val_loss: 9.9854 - val_mae: 2.5734 - val_mse: 9.9854\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6288 - mae: 1.3608 - mse: 3.6288 - val_loss: 9.7888 - val_mae: 2.4218 - val_mse: 9.7888\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9613 - mae: 1.1298 - mse: 2.9613 - val_loss: 8.3435 - val_mae: 2.2137 - val_mse: 8.3435\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3414 - mae: 1.2429 - mse: 3.3414 - val_loss: 10.6135 - val_mae: 2.5011 - val_mse: 10.6135\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1761 - mae: 1.1834 - mse: 3.1761 - val_loss: 8.9852 - val_mae: 2.3402 - val_mse: 8.9852\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1090 - mae: 1.2300 - mse: 3.1090 - val_loss: 8.5855 - val_mae: 2.2038 - val_mse: 8.5855\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2244 - mae: 1.2416 - mse: 3.2244 - val_loss: 8.1691 - val_mae: 2.0758 - val_mse: 8.1691\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5275 - mae: 1.3135 - mse: 3.5275 - val_loss: 8.4253 - val_mae: 2.2077 - val_mse: 8.4253\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0370 - mae: 1.4294 - mse: 4.0370 - val_loss: 9.7348 - val_mae: 2.2357 - val_mse: 9.7348\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9820 - mae: 1.2231 - mse: 2.9820 - val_loss: 8.2675 - val_mae: 2.2356 - val_mse: 8.2675\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3466 - mae: 1.1744 - mse: 3.3466 - val_loss: 8.5888 - val_mae: 2.2510 - val_mse: 8.5888\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6386 - mae: 1.5706 - mse: 5.6386 - val_loss: 12.1234 - val_mae: 2.6424 - val_mse: 12.1234\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7306 - mae: 1.3364 - mse: 3.7306 - val_loss: 8.7395 - val_mae: 2.2840 - val_mse: 8.7395\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8309 - mae: 1.3142 - mse: 3.8309 - val_loss: 7.6152 - val_mae: 2.1522 - val_mse: 7.6152\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8374 - mae: 1.1565 - mse: 2.8374 - val_loss: 8.2728 - val_mae: 2.2362 - val_mse: 8.2728\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8391 - mae: 1.1343 - mse: 2.8391 - val_loss: 9.0878 - val_mae: 2.2671 - val_mse: 9.0878\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8813 - mae: 1.1428 - mse: 2.8813 - val_loss: 9.4259 - val_mae: 2.4094 - val_mse: 9.4259\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4357 - mae: 1.2854 - mse: 3.4357 - val_loss: 8.0674 - val_mae: 2.1733 - val_mse: 8.0674\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8751 - mae: 1.1411 - mse: 2.8751 - val_loss: 8.2975 - val_mae: 2.2028 - val_mse: 8.2975\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8729 - mae: 1.1627 - mse: 2.8729 - val_loss: 7.3501 - val_mae: 2.0920 - val_mse: 7.3501\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4003 - mae: 1.3460 - mse: 3.4003 - val_loss: 9.3103 - val_mae: 2.3247 - val_mse: 9.3103\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0994 - mae: 1.1936 - mse: 3.0994 - val_loss: 10.8844 - val_mae: 2.5773 - val_mse: 10.8844\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3572 - mae: 1.3486 - mse: 3.3572 - val_loss: 10.7871 - val_mae: 2.5494 - val_mse: 10.7871\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0135 - mae: 1.1946 - mse: 3.0135 - val_loss: 7.3861 - val_mae: 2.1141 - val_mse: 7.3861\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6460 - mae: 1.2946 - mse: 3.6460 - val_loss: 7.5094 - val_mae: 2.0824 - val_mse: 7.5094\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0160 - mae: 1.2032 - mse: 3.0160 - val_loss: 7.9876 - val_mae: 2.2456 - val_mse: 7.9876\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8153 - mae: 1.1385 - mse: 2.8153 - val_loss: 8.2515 - val_mae: 2.1072 - val_mse: 8.2515\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6472 - mae: 1.1601 - mse: 2.6472 - val_loss: 7.8865 - val_mae: 2.2255 - val_mse: 7.8865\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6398 - mae: 1.1403 - mse: 2.6398 - val_loss: 8.6425 - val_mae: 2.2773 - val_mse: 8.6425\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6491 - mae: 1.1052 - mse: 2.6491 - val_loss: 8.2708 - val_mae: 2.2571 - val_mse: 8.2708\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8262 - mae: 1.1553 - mse: 2.8262 - val_loss: 8.5815 - val_mae: 2.1447 - val_mse: 8.5815\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8425 - mae: 1.3629 - mse: 3.8425 - val_loss: 8.0942 - val_mae: 2.1882 - val_mse: 8.0942\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5677 - mae: 1.3962 - mse: 4.5677 - val_loss: 10.0485 - val_mae: 2.4277 - val_mse: 10.0485\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0013 - mae: 1.4152 - mse: 4.0013 - val_loss: 7.7656 - val_mae: 2.1062 - val_mse: 7.7656\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2430 - mae: 1.2382 - mse: 3.2430 - val_loss: 8.6334 - val_mae: 2.2721 - val_mse: 8.6334\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8563 - mae: 1.1625 - mse: 2.8563 - val_loss: 11.0261 - val_mae: 2.5588 - val_mse: 11.0261\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6515 - mae: 1.3249 - mse: 3.6515 - val_loss: 9.5317 - val_mae: 2.5192 - val_mse: 9.5317\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7247 - mae: 1.3545 - mse: 3.7247 - val_loss: 16.5042 - val_mae: 3.0959 - val_mse: 16.5042\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1569 - mae: 1.4470 - mse: 4.1569 - val_loss: 8.4023 - val_mae: 2.2290 - val_mse: 8.4023\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2359 - mae: 1.2730 - mse: 3.2359 - val_loss: 8.5236 - val_mae: 2.2531 - val_mse: 8.5236\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7222 - mae: 1.1395 - mse: 2.7222 - val_loss: 8.2756 - val_mae: 2.2250 - val_mse: 8.2756\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0344 - mae: 1.2215 - mse: 3.0344 - val_loss: 8.5654 - val_mae: 2.2965 - val_mse: 8.5654\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7801 - mae: 1.1611 - mse: 2.7801 - val_loss: 7.9187 - val_mae: 2.1458 - val_mse: 7.9187\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7799 - mae: 1.1457 - mse: 2.7799 - val_loss: 8.0070 - val_mae: 2.1298 - val_mse: 8.0070\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0601 - mae: 1.2295 - mse: 3.0601 - val_loss: 7.2110 - val_mae: 1.9934 - val_mse: 7.2110\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3460 - mae: 1.3169 - mse: 3.3460 - val_loss: 8.9651 - val_mae: 2.1590 - val_mse: 8.9651\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3441 - mae: 1.5067 - mse: 4.3441 - val_loss: 8.9907 - val_mae: 2.2962 - val_mse: 8.9907\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8334 - mae: 1.3351 - mse: 3.8334 - val_loss: 8.1799 - val_mae: 2.1562 - val_mse: 8.1799\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8534 - mae: 1.1185 - mse: 2.8534 - val_loss: 7.4399 - val_mae: 2.0762 - val_mse: 7.4399\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7106 - mae: 1.1149 - mse: 2.7106 - val_loss: 9.6275 - val_mae: 2.2357 - val_mse: 9.6275\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5633 - mae: 1.1404 - mse: 2.5633 - val_loss: 8.7255 - val_mae: 2.2997 - val_mse: 8.7255\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8534 - mae: 1.1277 - mse: 2.8534 - val_loss: 8.0919 - val_mae: 2.2337 - val_mse: 8.0919\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9266 - mae: 1.3541 - mse: 3.9266 - val_loss: 9.8255 - val_mae: 2.4823 - val_mse: 9.8255\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0664 - mae: 1.1359 - mse: 3.0664 - val_loss: 9.2382 - val_mae: 2.1733 - val_mse: 9.2382\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6730 - mae: 1.3103 - mse: 3.6730 - val_loss: 9.5058 - val_mae: 2.2686 - val_mse: 9.5058\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0670 - mae: 1.2299 - mse: 3.0670 - val_loss: 9.1573 - val_mae: 2.3564 - val_mse: 9.1573\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1469 - mae: 1.3323 - mse: 4.1469 - val_loss: 9.8231 - val_mae: 2.2326 - val_mse: 9.8231\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9778 - mae: 1.4254 - mse: 3.9778 - val_loss: 10.2494 - val_mae: 2.3642 - val_mse: 10.2494\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3317 - mae: 1.2961 - mse: 3.3317 - val_loss: 8.9701 - val_mae: 2.2486 - val_mse: 8.9701\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2775 - mae: 1.2755 - mse: 3.2775 - val_loss: 10.4117 - val_mae: 2.4520 - val_mse: 10.4117\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8919 - mae: 1.1658 - mse: 2.8919 - val_loss: 8.3264 - val_mae: 2.2532 - val_mse: 8.3264\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7208 - mae: 1.1185 - mse: 2.7208 - val_loss: 8.1323 - val_mae: 2.1794 - val_mse: 8.1323\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7632 - mae: 1.3867 - mse: 3.7632 - val_loss: 10.2437 - val_mae: 2.4274 - val_mse: 10.2437\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5195 - mae: 1.3020 - mse: 3.5195 - val_loss: 9.4389 - val_mae: 2.2961 - val_mse: 9.4389\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1475 - mae: 1.2597 - mse: 3.1475 - val_loss: 10.9697 - val_mae: 2.4082 - val_mse: 10.9697\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1505 - mae: 1.1503 - mse: 3.1505 - val_loss: 8.1619 - val_mae: 2.1818 - val_mse: 8.1619\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3892 - mae: 1.2889 - mse: 3.3892 - val_loss: 8.4090 - val_mae: 2.1198 - val_mse: 8.4090\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3606 - mae: 1.2552 - mse: 3.3606 - val_loss: 8.6841 - val_mae: 2.2882 - val_mse: 8.6841\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0613 - mae: 1.2347 - mse: 3.0613 - val_loss: 9.6974 - val_mae: 2.3997 - val_mse: 9.6974\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7291 - mae: 1.1088 - mse: 2.7291 - val_loss: 9.8493 - val_mae: 2.4308 - val_mse: 9.8493\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7936 - mae: 1.1430 - mse: 2.7936 - val_loss: 8.1816 - val_mae: 2.2402 - val_mse: 8.1816\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5863 - mae: 1.0625 - mse: 2.5863 - val_loss: 9.9995 - val_mae: 2.4682 - val_mse: 9.9995\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2186 - mae: 1.2168 - mse: 3.2186 - val_loss: 8.7260 - val_mae: 2.3040 - val_mse: 8.7260\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5110 - mae: 1.0882 - mse: 2.5110 - val_loss: 9.5732 - val_mae: 2.2546 - val_mse: 9.5732\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9256 - mae: 1.1331 - mse: 2.9256 - val_loss: 8.1194 - val_mae: 2.2080 - val_mse: 8.1194\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4105 - mae: 1.0241 - mse: 2.4105 - val_loss: 8.1438 - val_mae: 2.2257 - val_mse: 8.1438\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4826 - mae: 1.0647 - mse: 2.4826 - val_loss: 8.5644 - val_mae: 2.3035 - val_mse: 8.5644\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2414 - mae: 1.0600 - mse: 2.2414 - val_loss: 8.2587 - val_mae: 2.2298 - val_mse: 8.2587\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.0193 - mae: 1.2107 - mse: 3.0193 - val_loss: 8.3986 - val_mae: 2.1088 - val_mse: 8.3986\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2363 - mae: 1.2881 - mse: 3.2363 - val_loss: 10.2441 - val_mae: 2.3215 - val_mse: 10.2441\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7158 - mae: 1.1299 - mse: 2.7158 - val_loss: 7.7607 - val_mae: 2.1378 - val_mse: 7.7607\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3234 - mae: 1.0483 - mse: 2.3234 - val_loss: 9.0681 - val_mae: 2.2110 - val_mse: 9.0681\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.6512 - mae: 1.4323 - mse: 4.6512 - val_loss: 7.9363 - val_mae: 2.2053 - val_mse: 7.9363\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3915 - mae: 1.7069 - mse: 5.3915 - val_loss: 10.2023 - val_mae: 2.4314 - val_mse: 10.2023\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7919 - mae: 1.1602 - mse: 2.7919 - val_loss: 7.4055 - val_mae: 2.0693 - val_mse: 7.4055\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3432 - mae: 1.0174 - mse: 2.3432 - val_loss: 11.4989 - val_mae: 2.6348 - val_mse: 11.4989\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2701 - mae: 1.2379 - mse: 3.2701 - val_loss: 9.0102 - val_mae: 2.3990 - val_mse: 9.0102\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0917 - mae: 1.2294 - mse: 3.0917 - val_loss: 12.0641 - val_mae: 2.6469 - val_mse: 12.0641\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1061 - mae: 1.2345 - mse: 3.1061 - val_loss: 7.5243 - val_mae: 2.1148 - val_mse: 7.5243\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5342 - mae: 1.0640 - mse: 2.5342 - val_loss: 7.4043 - val_mae: 2.0545 - val_mse: 7.4043\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5428 - mae: 1.2596 - mse: 3.5428 - val_loss: 12.5448 - val_mae: 2.7872 - val_mse: 12.5448\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5749 - mae: 1.5551 - mse: 4.5749 - val_loss: 9.4021 - val_mae: 2.2185 - val_mse: 9.4021\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5722 - mae: 1.1277 - mse: 2.5722 - val_loss: 7.5592 - val_mae: 2.1119 - val_mse: 7.5592\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6001 - mae: 1.0420 - mse: 2.6001 - val_loss: 7.0721 - val_mae: 2.0222 - val_mse: 7.0721\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1579 - mae: 1.1704 - mse: 3.1579 - val_loss: 8.7688 - val_mae: 2.2840 - val_mse: 8.7688\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7034 - mae: 1.1591 - mse: 2.7034 - val_loss: 8.8666 - val_mae: 2.3082 - val_mse: 8.8666\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0025 - mae: 1.1838 - mse: 3.0025 - val_loss: 7.5202 - val_mae: 2.0973 - val_mse: 7.5202\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4105 - mae: 1.0425 - mse: 2.4105 - val_loss: 7.5368 - val_mae: 2.1319 - val_mse: 7.5368\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5781 - mae: 1.0955 - mse: 2.5781 - val_loss: 7.6497 - val_mae: 2.0832 - val_mse: 7.6497\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3615 - mae: 1.0554 - mse: 2.3615 - val_loss: 7.7154 - val_mae: 2.1794 - val_mse: 7.7154\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4276 - mae: 0.9897 - mse: 2.4276 - val_loss: 7.6106 - val_mae: 2.0392 - val_mse: 7.6106\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5851 - mae: 1.1043 - mse: 2.5851 - val_loss: 11.3333 - val_mae: 2.6771 - val_mse: 11.3333\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2935 - mae: 1.2232 - mse: 3.2935 - val_loss: 8.9456 - val_mae: 2.2486 - val_mse: 8.9456\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7369 - mae: 1.1335 - mse: 2.7369 - val_loss: 8.0924 - val_mae: 2.1809 - val_mse: 8.0924\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4051 - mae: 1.0183 - mse: 2.4051 - val_loss: 8.1590 - val_mae: 2.2327 - val_mse: 8.1590\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5517 - mae: 1.0674 - mse: 2.5517 - val_loss: 11.5771 - val_mae: 2.4838 - val_mse: 11.5771\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.4307 - mae: 1.5788 - mse: 4.4307 - val_loss: 8.4291 - val_mae: 2.2398 - val_mse: 8.4291\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6599 - mae: 1.3319 - mse: 3.6599 - val_loss: 7.7320 - val_mae: 2.0669 - val_mse: 7.7320\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6835 - mae: 1.1199 - mse: 2.6835 - val_loss: 8.4119 - val_mae: 2.0761 - val_mse: 8.4119\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0915 - mae: 1.4621 - mse: 4.0915 - val_loss: 9.4951 - val_mae: 2.3885 - val_mse: 9.4951\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4372 - mae: 1.2486 - mse: 3.4372 - val_loss: 7.4438 - val_mae: 2.1322 - val_mse: 7.4438\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6245 - mae: 1.1250 - mse: 2.6245 - val_loss: 7.9552 - val_mae: 2.2581 - val_mse: 7.9552\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9040 - mae: 1.1869 - mse: 2.9040 - val_loss: 10.3235 - val_mae: 2.3048 - val_mse: 10.3235\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.1818 - mae: 1.2579 - mse: 3.1818 - val_loss: 7.5114 - val_mae: 2.0043 - val_mse: 7.5114\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8751 - mae: 1.1305 - mse: 2.8751 - val_loss: 10.2394 - val_mae: 2.4606 - val_mse: 10.2394\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1913 - mae: 1.1814 - mse: 3.1913 - val_loss: 7.9991 - val_mae: 2.0589 - val_mse: 7.9991\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2605 - mae: 1.0322 - mse: 2.2605 - val_loss: 7.5779 - val_mae: 2.0989 - val_mse: 7.5779\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1966 - mae: 1.2073 - mse: 3.1966 - val_loss: 10.8006 - val_mae: 2.6852 - val_mse: 10.8006\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0088 - mae: 1.1853 - mse: 3.0088 - val_loss: 7.9162 - val_mae: 2.0496 - val_mse: 7.9162\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3026 - mae: 1.0409 - mse: 2.3026 - val_loss: 8.7184 - val_mae: 2.2305 - val_mse: 8.7184\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3279 - mae: 1.2175 - mse: 3.3279 - val_loss: 11.4183 - val_mae: 2.5903 - val_mse: 11.4183\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8087 - mae: 1.1211 - mse: 2.8087 - val_loss: 7.3617 - val_mae: 2.0838 - val_mse: 7.3617\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2768 - mae: 1.0309 - mse: 2.2768 - val_loss: 8.4473 - val_mae: 2.2858 - val_mse: 8.4473\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5910 - mae: 1.0567 - mse: 2.5910 - val_loss: 8.9697 - val_mae: 2.3264 - val_mse: 8.9697\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2410 - mae: 0.9720 - mse: 2.2410 - val_loss: 8.1384 - val_mae: 2.1531 - val_mse: 8.1384\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7978 - mae: 1.0664 - mse: 2.7978 - val_loss: 7.5842 - val_mae: 2.0758 - val_mse: 7.5842\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3561 - mae: 1.0158 - mse: 2.3561 - val_loss: 8.7660 - val_mae: 2.1077 - val_mse: 8.7660\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6203 - mae: 1.2496 - mse: 3.6203 - val_loss: 8.2769 - val_mae: 2.2310 - val_mse: 8.2769\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9273 - mae: 1.1952 - mse: 2.9273 - val_loss: 11.5195 - val_mae: 2.7156 - val_mse: 11.5195\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5960 - mae: 1.1052 - mse: 2.5960 - val_loss: 9.4213 - val_mae: 2.4207 - val_mse: 9.4213\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2210 - mae: 0.9888 - mse: 2.2210 - val_loss: 7.4535 - val_mae: 2.0994 - val_mse: 7.4535\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2886 - mae: 1.0361 - mse: 2.2886 - val_loss: 9.8993 - val_mae: 2.3222 - val_mse: 9.8993\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1956 - mae: 1.0277 - mse: 2.1956 - val_loss: 8.1373 - val_mae: 2.2130 - val_mse: 8.1373\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5431 - mae: 1.0609 - mse: 2.5431 - val_loss: 8.4638 - val_mae: 2.2267 - val_mse: 8.4638\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3184 - mae: 1.0111 - mse: 2.3184 - val_loss: 8.4928 - val_mae: 2.2975 - val_mse: 8.4928\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4415 - mae: 1.0567 - mse: 2.4415 - val_loss: 8.6326 - val_mae: 2.1227 - val_mse: 8.6326\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2371 - mae: 0.9867 - mse: 2.2371 - val_loss: 8.1082 - val_mae: 2.1697 - val_mse: 8.1082\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2772 - mae: 0.9737 - mse: 2.2772 - val_loss: 7.5400 - val_mae: 2.1396 - val_mse: 7.5400\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4821 - mae: 1.0347 - mse: 2.4821 - val_loss: 8.3385 - val_mae: 2.0607 - val_mse: 8.3385\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3157 - mae: 1.0328 - mse: 2.3157 - val_loss: 8.7166 - val_mae: 2.1783 - val_mse: 8.7166\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9637 - mae: 1.1772 - mse: 2.9637 - val_loss: 8.7375 - val_mae: 2.3075 - val_mse: 8.7375\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9091 - mae: 1.1795 - mse: 2.9091 - val_loss: 8.7006 - val_mae: 2.3268 - val_mse: 8.7006\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3395 - mae: 0.9881 - mse: 2.3395 - val_loss: 8.9020 - val_mae: 2.3508 - val_mse: 8.9020\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2171 - mae: 1.0173 - mse: 2.2171 - val_loss: 7.9595 - val_mae: 2.2030 - val_mse: 7.9595\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1921 - mae: 1.3591 - mse: 4.1921 - val_loss: 8.4955 - val_mae: 2.1490 - val_mse: 8.4955\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6034 - mae: 1.0649 - mse: 2.6034 - val_loss: 8.6500 - val_mae: 2.3326 - val_mse: 8.6500\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0200 - mae: 0.9409 - mse: 2.0200 - val_loss: 8.0524 - val_mae: 2.1925 - val_mse: 8.0524\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1485 - mae: 0.9751 - mse: 2.1485 - val_loss: 8.0907 - val_mae: 2.1691 - val_mse: 8.0907\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1343 - mae: 0.9643 - mse: 2.1343 - val_loss: 9.2279 - val_mae: 2.2224 - val_mse: 9.2279\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7925 - mae: 1.1800 - mse: 2.7925 - val_loss: 13.8312 - val_mae: 2.8907 - val_mse: 13.8312\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5806 - mae: 1.3253 - mse: 3.5806 - val_loss: 7.9298 - val_mae: 2.2083 - val_mse: 7.9298\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4244 - mae: 1.0624 - mse: 2.4244 - val_loss: 8.5332 - val_mae: 2.2884 - val_mse: 8.5332\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1915 - mae: 1.0065 - mse: 2.1915 - val_loss: 9.5507 - val_mae: 2.4118 - val_mse: 9.5507\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6414 - mae: 1.1708 - mse: 2.6414 - val_loss: 8.3851 - val_mae: 2.2647 - val_mse: 8.3851\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9827 - mae: 0.9311 - mse: 1.9827 - val_loss: 8.0792 - val_mae: 2.1797 - val_mse: 8.0792\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1946 - mae: 0.9341 - mse: 2.1946 - val_loss: 8.1479 - val_mae: 2.2065 - val_mse: 8.1479\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5671 - mae: 1.0653 - mse: 2.5671 - val_loss: 8.7832 - val_mae: 2.3471 - val_mse: 8.7832\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2938 - mae: 1.0032 - mse: 2.2938 - val_loss: 9.6982 - val_mae: 2.4570 - val_mse: 9.6982\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1116 - mae: 0.9765 - mse: 2.1116 - val_loss: 7.3024 - val_mae: 2.0979 - val_mse: 7.3024\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1269 - mae: 0.9589 - mse: 2.1269 - val_loss: 7.8968 - val_mae: 2.2253 - val_mse: 7.8968\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2780 - mae: 1.0263 - mse: 2.2780 - val_loss: 7.4374 - val_mae: 2.0106 - val_mse: 7.4374\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2832 - mae: 0.9964 - mse: 2.2832 - val_loss: 7.8255 - val_mae: 2.1973 - val_mse: 7.8255\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3565 - mae: 1.0051 - mse: 2.3565 - val_loss: 8.2205 - val_mae: 2.2035 - val_mse: 8.2205\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2865 - mae: 0.9729 - mse: 2.2865 - val_loss: 8.4727 - val_mae: 2.3062 - val_mse: 8.4727\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3356 - mae: 1.0417 - mse: 2.3356 - val_loss: 8.0759 - val_mae: 2.1963 - val_mse: 8.0759\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4914 - mae: 1.0720 - mse: 2.4914 - val_loss: 8.5837 - val_mae: 2.3130 - val_mse: 8.5837\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0949 - mae: 0.9547 - mse: 2.0949 - val_loss: 9.0193 - val_mae: 2.3713 - val_mse: 9.0193\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7094 - mae: 1.4115 - mse: 3.7094 - val_loss: 10.5846 - val_mae: 2.5668 - val_mse: 10.5846\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3273 - mae: 1.0926 - mse: 2.3273 - val_loss: 8.0684 - val_mae: 2.1764 - val_mse: 8.0684\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3006 - mae: 1.0118 - mse: 2.3006 - val_loss: 8.5558 - val_mae: 2.2932 - val_mse: 8.5558\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2718 - mae: 1.0021 - mse: 2.2718 - val_loss: 10.4909 - val_mae: 2.5350 - val_mse: 10.4909\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3387 - mae: 1.0400 - mse: 2.3387 - val_loss: 9.2959 - val_mae: 2.4801 - val_mse: 9.2959\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1593 - mae: 1.0048 - mse: 2.1593 - val_loss: 8.6049 - val_mae: 2.3116 - val_mse: 8.6049\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3702 - mae: 1.2002 - mse: 3.3702 - val_loss: 8.7017 - val_mae: 2.2747 - val_mse: 8.7017\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8529 - mae: 1.1471 - mse: 2.8529 - val_loss: 8.2784 - val_mae: 2.1883 - val_mse: 8.2784\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1398 - mae: 0.9797 - mse: 2.1398 - val_loss: 8.9639 - val_mae: 2.3383 - val_mse: 8.9639\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3170 - mae: 1.3920 - mse: 4.3170 - val_loss: 9.1285 - val_mae: 2.3688 - val_mse: 9.1285\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9671 - mae: 1.2261 - mse: 2.9671 - val_loss: 10.5365 - val_mae: 2.6501 - val_mse: 10.5365\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2077 - mae: 1.0133 - mse: 2.2077 - val_loss: 7.8126 - val_mae: 2.1824 - val_mse: 7.8126\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1338 - mae: 0.9864 - mse: 2.1338 - val_loss: 8.0249 - val_mae: 2.2231 - val_mse: 8.0249\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3609 - mae: 1.0452 - mse: 2.3609 - val_loss: 7.5279 - val_mae: 2.0906 - val_mse: 7.5279\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0919 - mae: 0.9724 - mse: 2.0919 - val_loss: 8.4832 - val_mae: 2.2758 - val_mse: 8.4832\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0074 - mae: 0.9396 - mse: 2.0074 - val_loss: 8.3730 - val_mae: 2.1626 - val_mse: 8.3730\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5863 - mae: 1.1021 - mse: 2.5863 - val_loss: 8.8441 - val_mae: 2.3184 - val_mse: 8.8441\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3744 - mae: 1.0427 - mse: 2.3744 - val_loss: 8.0211 - val_mae: 2.1977 - val_mse: 8.0211\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1877 - mae: 0.9715 - mse: 2.1877 - val_loss: 8.3928 - val_mae: 2.1520 - val_mse: 8.3928\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7963 - mae: 1.1565 - mse: 2.7963 - val_loss: 8.0373 - val_mae: 2.2243 - val_mse: 8.0373\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8474 - mae: 1.0938 - mse: 2.8474 - val_loss: 8.1003 - val_mae: 2.1868 - val_mse: 8.1003\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9767 - mae: 1.1773 - mse: 2.9767 - val_loss: 8.6887 - val_mae: 2.0731 - val_mse: 8.6887\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6538 - mae: 1.1461 - mse: 2.6538 - val_loss: 11.1795 - val_mae: 2.5983 - val_mse: 11.1795\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8937 - mae: 1.1105 - mse: 2.8937 - val_loss: 13.3861 - val_mae: 2.9482 - val_mse: 13.3861\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6929 - mae: 1.0930 - mse: 2.6929 - val_loss: 8.9819 - val_mae: 2.1848 - val_mse: 8.9819\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3024 - mae: 1.0139 - mse: 2.3024 - val_loss: 8.8040 - val_mae: 2.3007 - val_mse: 8.8040\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9744 - mae: 0.9812 - mse: 1.9744 - val_loss: 8.0387 - val_mae: 2.1226 - val_mse: 8.0387\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2515 - mae: 1.0278 - mse: 2.2515 - val_loss: 10.2702 - val_mae: 2.5010 - val_mse: 10.2702\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9250 - mae: 1.3491 - mse: 3.9250 - val_loss: 7.5356 - val_mae: 2.1520 - val_mse: 7.5356\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5725 - mae: 1.1135 - mse: 2.5725 - val_loss: 8.3214 - val_mae: 2.2662 - val_mse: 8.3214\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0333 - mae: 0.9887 - mse: 2.0333 - val_loss: 8.1862 - val_mae: 2.1757 - val_mse: 8.1862\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9775 - mae: 0.9297 - mse: 1.9775 - val_loss: 10.3708 - val_mae: 2.5392 - val_mse: 10.3708\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4014 - mae: 1.0801 - mse: 2.4014 - val_loss: 7.9252 - val_mae: 2.1885 - val_mse: 7.9252\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6386 - mae: 1.0301 - mse: 2.6386 - val_loss: 8.3813 - val_mae: 2.1605 - val_mse: 8.3813\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2874 - mae: 1.2781 - mse: 3.2874 - val_loss: 9.6568 - val_mae: 2.3688 - val_mse: 9.6568\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4662 - mae: 1.0885 - mse: 2.4662 - val_loss: 8.5546 - val_mae: 2.2823 - val_mse: 8.5546\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9549 - mae: 1.0874 - mse: 2.9549 - val_loss: 8.1325 - val_mae: 2.1364 - val_mse: 8.1325\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3652 - mae: 1.0987 - mse: 2.3652 - val_loss: 9.8165 - val_mae: 2.3843 - val_mse: 9.8165\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9721 - mae: 1.3829 - mse: 3.9721 - val_loss: 7.6333 - val_mae: 2.0869 - val_mse: 7.6333\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2297 - mae: 1.0119 - mse: 2.2297 - val_loss: 10.8377 - val_mae: 2.5597 - val_mse: 10.8377\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7212 - mae: 1.1840 - mse: 2.7212 - val_loss: 7.4310 - val_mae: 2.0504 - val_mse: 7.4310\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1750 - mae: 1.0151 - mse: 2.1750 - val_loss: 8.6573 - val_mae: 2.1247 - val_mse: 8.6573\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9639 - mae: 0.9718 - mse: 1.9639 - val_loss: 8.1836 - val_mae: 2.2368 - val_mse: 8.1836\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0048 - mae: 0.9149 - mse: 2.0048 - val_loss: 7.4656 - val_mae: 2.1274 - val_mse: 7.4656\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4972 - mae: 1.0742 - mse: 2.4972 - val_loss: 7.7980 - val_mae: 2.1645 - val_mse: 7.7980\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4926 - mae: 1.0734 - mse: 2.4926 - val_loss: 8.2790 - val_mae: 2.1471 - val_mse: 8.2790\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8930 - mae: 0.9192 - mse: 1.8930 - val_loss: 8.5142 - val_mae: 2.3062 - val_mse: 8.5142\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0332 - mae: 0.9342 - mse: 2.0332 - val_loss: 8.4799 - val_mae: 2.2798 - val_mse: 8.4799\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9803 - mae: 0.9155 - mse: 1.9803 - val_loss: 8.4299 - val_mae: 2.0809 - val_mse: 8.4299\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3802 - mae: 1.0834 - mse: 2.3802 - val_loss: 9.7087 - val_mae: 2.1888 - val_mse: 9.7087\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8325 - mae: 1.1222 - mse: 2.8325 - val_loss: 7.5719 - val_mae: 2.0662 - val_mse: 7.5719\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9643 - mae: 0.9112 - mse: 1.9643 - val_loss: 9.5430 - val_mae: 2.2026 - val_mse: 9.5430\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4656 - mae: 1.5023 - mse: 4.4656 - val_loss: 8.5248 - val_mae: 2.2622 - val_mse: 8.5248\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2579 - mae: 1.3480 - mse: 3.2579 - val_loss: 8.3917 - val_mae: 2.2601 - val_mse: 8.3917\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0756 - mae: 0.9468 - mse: 2.0756 - val_loss: 9.1561 - val_mae: 2.4177 - val_mse: 9.1561\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4080 - mae: 1.1171 - mse: 2.4080 - val_loss: 8.7527 - val_mae: 2.3377 - val_mse: 8.7527\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5093 - mae: 1.0547 - mse: 2.5093 - val_loss: 8.4402 - val_mae: 2.2973 - val_mse: 8.4402\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1303 - mae: 0.9881 - mse: 2.1303 - val_loss: 7.9513 - val_mae: 2.2179 - val_mse: 7.9513\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2502 - mae: 0.9957 - mse: 2.2502 - val_loss: 7.8787 - val_mae: 2.0930 - val_mse: 7.8787\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0404 - mae: 0.9474 - mse: 2.0404 - val_loss: 7.7687 - val_mae: 2.1674 - val_mse: 7.7687\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8671 - mae: 0.8489 - mse: 1.8671 - val_loss: 10.7528 - val_mae: 2.2649 - val_mse: 10.7528\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3232 - mae: 1.0716 - mse: 2.3232 - val_loss: 7.9790 - val_mae: 2.1276 - val_mse: 7.9790\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0473 - mae: 0.9668 - mse: 2.0473 - val_loss: 8.1194 - val_mae: 2.2040 - val_mse: 8.1194\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1930 - mae: 0.9471 - mse: 2.1930 - val_loss: 7.9089 - val_mae: 2.2036 - val_mse: 7.9089\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9846 - mae: 0.9621 - mse: 1.9846 - val_loss: 7.9442 - val_mae: 2.2112 - val_mse: 7.9442\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5732 - mae: 1.0618 - mse: 2.5732 - val_loss: 8.1540 - val_mae: 2.0444 - val_mse: 8.1540\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9614 - mae: 0.9526 - mse: 1.9614 - val_loss: 8.3470 - val_mae: 2.2991 - val_mse: 8.3470\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1565 - mae: 0.9642 - mse: 2.1565 - val_loss: 9.0278 - val_mae: 2.3905 - val_mse: 9.0278\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9414 - mae: 0.9300 - mse: 1.9414 - val_loss: 8.2066 - val_mae: 2.1302 - val_mse: 8.2066\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7663 - mae: 0.8785 - mse: 1.7663 - val_loss: 8.2313 - val_mae: 2.2319 - val_mse: 8.2313\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8729 - mae: 0.8954 - mse: 1.8729 - val_loss: 8.1833 - val_mae: 2.2443 - val_mse: 8.1833\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1780 - mae: 0.9993 - mse: 2.1780 - val_loss: 7.7133 - val_mae: 2.1484 - val_mse: 7.7133\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4228 - mae: 1.0613 - mse: 2.4228 - val_loss: 9.5088 - val_mae: 2.4322 - val_mse: 9.5088\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1053 - mae: 1.0059 - mse: 2.1053 - val_loss: 9.2510 - val_mae: 2.4291 - val_mse: 9.2510\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8626 - mae: 0.9205 - mse: 1.8626 - val_loss: 8.2541 - val_mae: 2.2430 - val_mse: 8.2541\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9329 - mae: 0.9146 - mse: 1.9329 - val_loss: 11.4893 - val_mae: 2.5243 - val_mse: 11.4893\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1556 - mae: 0.9491 - mse: 2.1556 - val_loss: 8.0003 - val_mae: 2.2018 - val_mse: 8.0003\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6985 - mae: 0.8352 - mse: 1.6985 - val_loss: 8.2580 - val_mae: 2.2254 - val_mse: 8.2580\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3202 - mae: 1.0159 - mse: 2.3202 - val_loss: 9.7126 - val_mae: 2.2699 - val_mse: 9.7126\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7355 - mae: 0.8950 - mse: 1.7355 - val_loss: 7.9037 - val_mae: 2.1499 - val_mse: 7.9037\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5384 - mae: 1.0832 - mse: 2.5384 - val_loss: 8.7015 - val_mae: 2.0560 - val_mse: 8.7015\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2284 - mae: 1.0240 - mse: 2.2284 - val_loss: 7.8629 - val_mae: 2.1236 - val_mse: 7.8629\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4087 - mae: 1.0950 - mse: 2.4087 - val_loss: 9.9031 - val_mae: 2.5152 - val_mse: 9.9031\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4223 - mae: 1.0856 - mse: 2.4223 - val_loss: 7.8994 - val_mae: 2.1549 - val_mse: 7.8994\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9319 - mae: 0.9135 - mse: 1.9319 - val_loss: 8.0720 - val_mae: 2.0877 - val_mse: 8.0720\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5563 - mae: 1.0269 - mse: 2.5563 - val_loss: 9.1126 - val_mae: 2.0925 - val_mse: 9.1126\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6740 - mae: 1.5043 - mse: 4.6740 - val_loss: 7.9671 - val_mae: 2.1402 - val_mse: 7.9671\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7323 - mae: 1.3795 - mse: 3.7323 - val_loss: 7.2307 - val_mae: 2.0107 - val_mse: 7.2307\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1933 - mae: 0.9857 - mse: 2.1933 - val_loss: 7.6183 - val_mae: 2.0368 - val_mse: 7.6183\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.0353 - mae: 1.1414 - mse: 3.0353 - val_loss: 7.8359 - val_mae: 2.1572 - val_mse: 7.8359\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8592 - mae: 0.9117 - mse: 1.8592 - val_loss: 7.4481 - val_mae: 2.1152 - val_mse: 7.4481\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9516 - mae: 0.9086 - mse: 1.9516 - val_loss: 10.0346 - val_mae: 2.5577 - val_mse: 10.0346\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7016 - mae: 0.8701 - mse: 1.7016 - val_loss: 8.5607 - val_mae: 2.1858 - val_mse: 8.5607\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8135 - mae: 0.9062 - mse: 1.8135 - val_loss: 8.5024 - val_mae: 2.2625 - val_mse: 8.5024\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1987 - mae: 0.9850 - mse: 2.1987 - val_loss: 8.5108 - val_mae: 2.0970 - val_mse: 8.5108\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6804 - mae: 1.1410 - mse: 2.6804 - val_loss: 9.0102 - val_mae: 2.0815 - val_mse: 9.0102\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2520 - mae: 1.0228 - mse: 2.2520 - val_loss: 8.9496 - val_mae: 2.2512 - val_mse: 8.9496\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1466 - mae: 1.0531 - mse: 2.1466 - val_loss: 13.0545 - val_mae: 2.7149 - val_mse: 13.0545\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2222 - mae: 0.9417 - mse: 2.2222 - val_loss: 8.2955 - val_mae: 2.2196 - val_mse: 8.2955\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4675 - mae: 1.0172 - mse: 2.4675 - val_loss: 13.0950 - val_mae: 2.8617 - val_mse: 13.0950\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4791 - mae: 1.0227 - mse: 2.4791 - val_loss: 8.1757 - val_mae: 2.2325 - val_mse: 8.1757\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1470 - mae: 0.9612 - mse: 2.1470 - val_loss: 8.6643 - val_mae: 2.2564 - val_mse: 8.6643\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8607 - mae: 0.8755 - mse: 1.8607 - val_loss: 7.9889 - val_mae: 2.1593 - val_mse: 7.9889\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2177 - mae: 0.9740 - mse: 2.2177 - val_loss: 9.9350 - val_mae: 2.2355 - val_mse: 9.9350\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0998 - mae: 0.9197 - mse: 2.0998 - val_loss: 8.7791 - val_mae: 2.3054 - val_mse: 8.7791\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0111 - mae: 0.9088 - mse: 2.0111 - val_loss: 9.6460 - val_mae: 2.2297 - val_mse: 9.6460\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1734 - mae: 1.0255 - mse: 2.1734 - val_loss: 9.4683 - val_mae: 2.3938 - val_mse: 9.4683\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8659 - mae: 0.9187 - mse: 1.8659 - val_loss: 9.0900 - val_mae: 2.3651 - val_mse: 9.0900\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7190 - mae: 0.8603 - mse: 1.7190 - val_loss: 8.2441 - val_mae: 2.1891 - val_mse: 8.2441\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8408 - mae: 0.9086 - mse: 1.8408 - val_loss: 8.5232 - val_mae: 2.3052 - val_mse: 8.5232\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8175 - mae: 0.9055 - mse: 1.8175 - val_loss: 9.0084 - val_mae: 2.3314 - val_mse: 9.0084\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6290 - mae: 0.8412 - mse: 1.6290 - val_loss: 8.4937 - val_mae: 2.1315 - val_mse: 8.4937\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8402 - mae: 0.8862 - mse: 1.8402 - val_loss: 8.1902 - val_mae: 2.1246 - val_mse: 8.1902\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1299 - mae: 1.0216 - mse: 2.1299 - val_loss: 8.8535 - val_mae: 2.2810 - val_mse: 8.8535\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8131 - mae: 0.8810 - mse: 1.8131 - val_loss: 8.2961 - val_mae: 2.2024 - val_mse: 8.2961\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6928 - mae: 0.8458 - mse: 1.6928 - val_loss: 7.5201 - val_mae: 2.0551 - val_mse: 7.5201\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4765 - mae: 1.0888 - mse: 2.4765 - val_loss: 12.0829 - val_mae: 2.7986 - val_mse: 12.0829\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8138 - mae: 1.1893 - mse: 2.8138 - val_loss: 8.2410 - val_mae: 2.1109 - val_mse: 8.2410\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7417 - mae: 0.8838 - mse: 1.7417 - val_loss: 8.4168 - val_mae: 2.2509 - val_mse: 8.4168\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2961 - mae: 1.0331 - mse: 2.2961 - val_loss: 8.2188 - val_mae: 2.1975 - val_mse: 8.2188\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6233 - mae: 0.8129 - mse: 1.6233 - val_loss: 10.9976 - val_mae: 2.3085 - val_mse: 10.9976\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4271 - mae: 1.0797 - mse: 2.4271 - val_loss: 8.6889 - val_mae: 2.3233 - val_mse: 8.6889\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8497 - mae: 0.8867 - mse: 1.8497 - val_loss: 8.0880 - val_mae: 2.1543 - val_mse: 8.0880\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2188 - mae: 1.0722 - mse: 2.2188 - val_loss: 9.0474 - val_mae: 2.3289 - val_mse: 9.0474\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6716 - mae: 1.1071 - mse: 2.6716 - val_loss: 8.2843 - val_mae: 2.2243 - val_mse: 8.2843\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7497 - mae: 0.8918 - mse: 1.7497 - val_loss: 8.4151 - val_mae: 2.2117 - val_mse: 8.4151\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6526 - mae: 0.8183 - mse: 1.6526 - val_loss: 9.5977 - val_mae: 2.4418 - val_mse: 9.5977\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9077 - mae: 0.9292 - mse: 1.9077 - val_loss: 8.5961 - val_mae: 2.2468 - val_mse: 8.5961\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8618 - mae: 0.8709 - mse: 1.8618 - val_loss: 9.6156 - val_mae: 2.4435 - val_mse: 9.6156\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9759 - mae: 1.2280 - mse: 2.9759 - val_loss: 9.0650 - val_mae: 2.3342 - val_mse: 9.0650\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8264 - mae: 0.8791 - mse: 1.8264 - val_loss: 7.7043 - val_mae: 2.0413 - val_mse: 7.7043\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8128 - mae: 0.8734 - mse: 1.8128 - val_loss: 9.5068 - val_mae: 2.3977 - val_mse: 9.5068\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7680 - mae: 0.8900 - mse: 1.7680 - val_loss: 7.6865 - val_mae: 2.1310 - val_mse: 7.6865\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0024 - mae: 0.9245 - mse: 2.0024 - val_loss: 9.6450 - val_mae: 2.4422 - val_mse: 9.6450\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6871 - mae: 0.8552 - mse: 1.6871 - val_loss: 8.1748 - val_mae: 2.1370 - val_mse: 8.1748\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6495 - mae: 0.8391 - mse: 1.6495 - val_loss: 8.1450 - val_mae: 2.1996 - val_mse: 8.1450\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9979 - mae: 0.9589 - mse: 1.9979 - val_loss: 7.5249 - val_mae: 2.0175 - val_mse: 7.5249\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9953 - mae: 1.1091 - mse: 2.9953 - val_loss: 9.8828 - val_mae: 2.5089 - val_mse: 9.8828\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9417 - mae: 1.2438 - mse: 2.9417 - val_loss: 8.0937 - val_mae: 2.1135 - val_mse: 8.0937\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0237 - mae: 0.9475 - mse: 2.0237 - val_loss: 8.3133 - val_mae: 2.1626 - val_mse: 8.3133\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7586 - mae: 0.8812 - mse: 1.7586 - val_loss: 8.2097 - val_mae: 2.1560 - val_mse: 8.2097\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5819 - mae: 0.7751 - mse: 1.5819 - val_loss: 9.2878 - val_mae: 2.1256 - val_mse: 9.2878\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3717 - mae: 1.0953 - mse: 2.3717 - val_loss: 8.9407 - val_mae: 2.3146 - val_mse: 8.9407\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9687 - mae: 0.9093 - mse: 1.9687 - val_loss: 9.4829 - val_mae: 2.1561 - val_mse: 9.4829\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5908 - mae: 1.0732 - mse: 2.5908 - val_loss: 8.5521 - val_mae: 2.2163 - val_mse: 8.5521\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8423 - mae: 0.8880 - mse: 1.8423 - val_loss: 8.4219 - val_mae: 2.2557 - val_mse: 8.4219\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6425 - mae: 0.8087 - mse: 1.6425 - val_loss: 8.0043 - val_mae: 2.1744 - val_mse: 8.0043\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9644 - mae: 0.9078 - mse: 1.9644 - val_loss: 8.9240 - val_mae: 2.3487 - val_mse: 8.9240\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7098 - mae: 1.6987 - mse: 5.7098 - val_loss: 10.0859 - val_mae: 2.4362 - val_mse: 10.0859\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8255 - mae: 1.1443 - mse: 2.8255 - val_loss: 11.2831 - val_mae: 2.6516 - val_mse: 11.2831\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1305 - mae: 1.0050 - mse: 2.1305 - val_loss: 8.6805 - val_mae: 2.2578 - val_mse: 8.6805\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8562 - mae: 0.9216 - mse: 1.8562 - val_loss: 8.6048 - val_mae: 2.2601 - val_mse: 8.6048\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3285 - mae: 1.0133 - mse: 2.3285 - val_loss: 7.9130 - val_mae: 2.0954 - val_mse: 7.9130\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7634 - mae: 0.8933 - mse: 1.7634 - val_loss: 9.1774 - val_mae: 2.3114 - val_mse: 9.1774\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9452 - mae: 0.9549 - mse: 1.9452 - val_loss: 8.0731 - val_mae: 2.1608 - val_mse: 8.0731\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6286 - mae: 0.8391 - mse: 1.6286 - val_loss: 8.6324 - val_mae: 2.2685 - val_mse: 8.6324\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1748 - mae: 0.9469 - mse: 2.1748 - val_loss: 10.4046 - val_mae: 2.1921 - val_mse: 10.4046\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1158 - mae: 0.9713 - mse: 2.1158 - val_loss: 8.7813 - val_mae: 2.2808 - val_mse: 8.7813\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5829 - mae: 0.8490 - mse: 1.5829 - val_loss: 8.2658 - val_mae: 2.1913 - val_mse: 8.2658\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7328 - mae: 0.8388 - mse: 1.7328 - val_loss: 9.7180 - val_mae: 2.4230 - val_mse: 9.7180\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1415 - mae: 0.9744 - mse: 2.1415 - val_loss: 8.0243 - val_mae: 2.1628 - val_mse: 8.0243\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5249 - mae: 0.7823 - mse: 1.5249 - val_loss: 9.6744 - val_mae: 2.4343 - val_mse: 9.6744\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1869 - mae: 1.0066 - mse: 2.1869 - val_loss: 8.3889 - val_mae: 2.2252 - val_mse: 8.3889\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8662 - mae: 0.9130 - mse: 1.8662 - val_loss: 9.1741 - val_mae: 2.3893 - val_mse: 9.1741\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8677 - mae: 0.8691 - mse: 1.8677 - val_loss: 8.2566 - val_mae: 2.1668 - val_mse: 8.2566\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5635 - mae: 0.8053 - mse: 1.5635 - val_loss: 8.8473 - val_mae: 2.3088 - val_mse: 8.8473\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8565 - mae: 0.9542 - mse: 1.8565 - val_loss: 8.9070 - val_mae: 2.3049 - val_mse: 8.9070\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6928 - mae: 0.8502 - mse: 1.6928 - val_loss: 10.7487 - val_mae: 2.2516 - val_mse: 10.7487\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5378 - mae: 1.1924 - mse: 2.5378 - val_loss: 8.9820 - val_mae: 2.2742 - val_mse: 8.9820\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1669 - mae: 0.9650 - mse: 2.1669 - val_loss: 9.0940 - val_mae: 2.3075 - val_mse: 9.0940\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6076 - mae: 0.8503 - mse: 1.6076 - val_loss: 10.8535 - val_mae: 2.2714 - val_mse: 10.8535\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3082 - mae: 1.4232 - mse: 4.3082 - val_loss: 8.2369 - val_mae: 2.1490 - val_mse: 8.2369\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2339 - mae: 1.0275 - mse: 2.2339 - val_loss: 8.7109 - val_mae: 2.2840 - val_mse: 8.7109\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6559 - mae: 0.8425 - mse: 1.6559 - val_loss: 8.9447 - val_mae: 2.1612 - val_mse: 8.9447\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1843 - mae: 0.9199 - mse: 2.1843 - val_loss: 9.9599 - val_mae: 2.4567 - val_mse: 9.9599\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8671 - mae: 0.9223 - mse: 1.8671 - val_loss: 9.1839 - val_mae: 2.3531 - val_mse: 9.1839\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3842 - mae: 1.0388 - mse: 2.3842 - val_loss: 8.6774 - val_mae: 2.2171 - val_mse: 8.6774\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7912 - mae: 0.8652 - mse: 1.7912 - val_loss: 8.6951 - val_mae: 2.2735 - val_mse: 8.6951\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1173 - mae: 0.9386 - mse: 2.1173 - val_loss: 9.9853 - val_mae: 2.3030 - val_mse: 9.9853\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0144 - mae: 0.9552 - mse: 2.0144 - val_loss: 8.7312 - val_mae: 2.2549 - val_mse: 8.7312\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5561 - mae: 0.8129 - mse: 1.5561 - val_loss: 8.2586 - val_mae: 2.1484 - val_mse: 8.2586\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6655 - mae: 0.8496 - mse: 1.6655 - val_loss: 10.6535 - val_mae: 2.2336 - val_mse: 10.6535\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6862 - mae: 1.3507 - mse: 3.6862 - val_loss: 8.4406 - val_mae: 2.1874 - val_mse: 8.4406\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6951 - mae: 0.8224 - mse: 1.6951 - val_loss: 8.1695 - val_mae: 2.0583 - val_mse: 8.1695\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8173 - mae: 0.9313 - mse: 1.8173 - val_loss: 7.9517 - val_mae: 2.0989 - val_mse: 7.9517\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6313 - mae: 0.8160 - mse: 1.6313 - val_loss: 8.8734 - val_mae: 2.2263 - val_mse: 8.8734\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9088 - mae: 0.8342 - mse: 1.9088 - val_loss: 9.5501 - val_mae: 2.3847 - val_mse: 9.5501\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6876 - mae: 0.8373 - mse: 1.6876 - val_loss: 7.9641 - val_mae: 2.0819 - val_mse: 7.9641\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1729 - mae: 0.8741 - mse: 2.1729 - val_loss: 8.5415 - val_mae: 2.2034 - val_mse: 8.5415\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6786 - mae: 0.8789 - mse: 1.6786 - val_loss: 8.3541 - val_mae: 2.2038 - val_mse: 8.3541\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5545 - mae: 0.8160 - mse: 1.5545 - val_loss: 8.6256 - val_mae: 2.2446 - val_mse: 8.6256\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7476 - mae: 0.8601 - mse: 1.7476 - val_loss: 8.4251 - val_mae: 2.1703 - val_mse: 8.4251\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4361 - mae: 1.0887 - mse: 2.4361 - val_loss: 9.6603 - val_mae: 2.3958 - val_mse: 9.6603\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8521 - mae: 1.1600 - mse: 2.8521 - val_loss: 7.8249 - val_mae: 2.0957 - val_mse: 7.8249\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6983 - mae: 0.8537 - mse: 1.6983 - val_loss: 9.4086 - val_mae: 2.3360 - val_mse: 9.4086\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5452 - mae: 0.8238 - mse: 1.5452 - val_loss: 8.4052 - val_mae: 2.2142 - val_mse: 8.4052\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9700 - mae: 0.8806 - mse: 1.9700 - val_loss: 9.2523 - val_mae: 2.2770 - val_mse: 9.2523\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6661 - mae: 0.8211 - mse: 1.6661 - val_loss: 9.1082 - val_mae: 2.3081 - val_mse: 9.1082\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0460 - mae: 0.9068 - mse: 2.0460 - val_loss: 10.1617 - val_mae: 2.2399 - val_mse: 10.1617\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2664 - mae: 1.0541 - mse: 2.2664 - val_loss: 9.5820 - val_mae: 2.3643 - val_mse: 9.5820\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7916 - mae: 0.9276 - mse: 1.7916 - val_loss: 8.8998 - val_mae: 2.2815 - val_mse: 8.8998\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8908 - mae: 0.8435 - mse: 1.8908 - val_loss: 10.7017 - val_mae: 2.5023 - val_mse: 10.7017\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0234 - mae: 1.0133 - mse: 2.0234 - val_loss: 8.7011 - val_mae: 2.1834 - val_mse: 8.7011\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4391 - mae: 0.7953 - mse: 1.4391 - val_loss: 8.7866 - val_mae: 2.1240 - val_mse: 8.7866\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3216 - mae: 0.9009 - mse: 2.3216 - val_loss: 9.1681 - val_mae: 2.2965 - val_mse: 9.1681\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5219 - mae: 0.7850 - mse: 1.5219 - val_loss: 9.1235 - val_mae: 2.1831 - val_mse: 9.1235\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8165 - mae: 0.9270 - mse: 1.8165 - val_loss: 9.3108 - val_mae: 2.3545 - val_mse: 9.3108\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5852 - mae: 0.7886 - mse: 1.5852 - val_loss: 8.8865 - val_mae: 2.2619 - val_mse: 8.8865\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3407 - mae: 0.9849 - mse: 2.3407 - val_loss: 8.5019 - val_mae: 2.1942 - val_mse: 8.5019\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8280 - mae: 0.8497 - mse: 1.8280 - val_loss: 8.2275 - val_mae: 2.1376 - val_mse: 8.2275\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7250 - mae: 0.8418 - mse: 1.7250 - val_loss: 9.0000 - val_mae: 2.2497 - val_mse: 9.0000\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4688 - mae: 0.7679 - mse: 1.4688 - val_loss: 8.9886 - val_mae: 2.2769 - val_mse: 8.9886\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3047 - mae: 0.7155 - mse: 1.3047 - val_loss: 8.8178 - val_mae: 2.1374 - val_mse: 8.8178\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8986 - mae: 0.8608 - mse: 1.8986 - val_loss: 9.2779 - val_mae: 2.2820 - val_mse: 9.2779\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3690 - mae: 1.0718 - mse: 2.3690 - val_loss: 10.3656 - val_mae: 2.5073 - val_mse: 10.3656\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4394 - mae: 0.7534 - mse: 1.4394 - val_loss: 9.0589 - val_mae: 2.1611 - val_mse: 9.0589\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6732 - mae: 0.8198 - mse: 1.6732 - val_loss: 9.5804 - val_mae: 2.3661 - val_mse: 9.5804\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5212 - mae: 0.7702 - mse: 1.5212 - val_loss: 9.8175 - val_mae: 2.2135 - val_mse: 9.8175\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8365 - mae: 0.8796 - mse: 1.8365 - val_loss: 8.7841 - val_mae: 2.1677 - val_mse: 8.7841\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4289 - mae: 1.1040 - mse: 2.4289 - val_loss: 9.3107 - val_mae: 2.3812 - val_mse: 9.3107\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1570 - mae: 0.9601 - mse: 2.1570 - val_loss: 8.0014 - val_mae: 2.0601 - val_mse: 8.0014\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7967 - mae: 0.9185 - mse: 1.7967 - val_loss: 8.4238 - val_mae: 2.1869 - val_mse: 8.4238\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7087 - mae: 0.8283 - mse: 1.7087 - val_loss: 8.3057 - val_mae: 2.1536 - val_mse: 8.3057\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5490 - mae: 0.7973 - mse: 1.5490 - val_loss: 8.3653 - val_mae: 2.1441 - val_mse: 8.3653\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5097 - mae: 1.0574 - mse: 2.5097 - val_loss: 9.4091 - val_mae: 2.3343 - val_mse: 9.4091\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4882 - mae: 0.7872 - mse: 1.4882 - val_loss: 10.0976 - val_mae: 2.2066 - val_mse: 10.0976\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6173 - mae: 1.1069 - mse: 2.6173 - val_loss: 8.5075 - val_mae: 2.2418 - val_mse: 8.5075\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8439 - mae: 0.9317 - mse: 1.8439 - val_loss: 10.7010 - val_mae: 2.5464 - val_mse: 10.7010\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2828 - mae: 1.0252 - mse: 2.2828 - val_loss: 9.0230 - val_mae: 2.2782 - val_mse: 9.0230\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0570 - mae: 0.9627 - mse: 2.0570 - val_loss: 9.9507 - val_mae: 2.1771 - val_mse: 9.9507\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8395 - mae: 0.9315 - mse: 1.8395 - val_loss: 9.3200 - val_mae: 2.2847 - val_mse: 9.3200\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6973 - mae: 0.8426 - mse: 1.6973 - val_loss: 9.3209 - val_mae: 2.4005 - val_mse: 9.3209\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8759 - mae: 0.9265 - mse: 1.8759 - val_loss: 8.7181 - val_mae: 2.2355 - val_mse: 8.7181\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5354 - mae: 0.7657 - mse: 1.5354 - val_loss: 8.6735 - val_mae: 2.2107 - val_mse: 8.6735\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4007 - mae: 0.7796 - mse: 1.4007 - val_loss: 8.4087 - val_mae: 2.2248 - val_mse: 8.4087\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4765 - mae: 0.7534 - mse: 1.4765 - val_loss: 8.4528 - val_mae: 2.1848 - val_mse: 8.4528\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4834 - mae: 0.7764 - mse: 1.4834 - val_loss: 8.8401 - val_mae: 2.1915 - val_mse: 8.8401\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7372 - mae: 0.8281 - mse: 1.7372 - val_loss: 9.2083 - val_mae: 2.3395 - val_mse: 9.2083\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9528 - mae: 0.9413 - mse: 1.9528 - val_loss: 10.6468 - val_mae: 2.5534 - val_mse: 10.6468\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5120 - mae: 0.8395 - mse: 1.5120 - val_loss: 8.7612 - val_mae: 2.1389 - val_mse: 8.7612\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8475 - mae: 0.9372 - mse: 1.8475 - val_loss: 8.6116 - val_mae: 2.1840 - val_mse: 8.6116\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5625 - mae: 0.8270 - mse: 1.5625 - val_loss: 8.1723 - val_mae: 2.1755 - val_mse: 8.1723\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5239 - mae: 0.7800 - mse: 1.5239 - val_loss: 10.3053 - val_mae: 2.5062 - val_mse: 10.3053\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4885 - mae: 0.7954 - mse: 1.4885 - val_loss: 9.7703 - val_mae: 2.3927 - val_mse: 9.7703\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9421 - mae: 0.9071 - mse: 1.9421 - val_loss: 8.9386 - val_mae: 2.2184 - val_mse: 8.9386\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3455 - mae: 1.0150 - mse: 2.3455 - val_loss: 9.3850 - val_mae: 2.3754 - val_mse: 9.3850\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7545 - mae: 0.8595 - mse: 1.7545 - val_loss: 8.2464 - val_mae: 2.1297 - val_mse: 8.2464\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4796 - mae: 0.7560 - mse: 1.4796 - val_loss: 8.7998 - val_mae: 2.2936 - val_mse: 8.7998\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0451 - mae: 0.9780 - mse: 2.0451 - val_loss: 8.4362 - val_mae: 2.1896 - val_mse: 8.4362\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7717 - mae: 0.9178 - mse: 1.7717 - val_loss: 8.0445 - val_mae: 2.0639 - val_mse: 8.0445\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9050 - mae: 0.9466 - mse: 1.9050 - val_loss: 8.7098 - val_mae: 2.1475 - val_mse: 8.7098\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0198 - mae: 0.9306 - mse: 2.0198 - val_loss: 8.9633 - val_mae: 2.3077 - val_mse: 8.9633\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4686 - mae: 0.7904 - mse: 1.4686 - val_loss: 8.2313 - val_mae: 2.1556 - val_mse: 8.2313\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7793 - mae: 0.8312 - mse: 1.7793 - val_loss: 8.9292 - val_mae: 2.2837 - val_mse: 8.9292\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7646 - mae: 0.8801 - mse: 1.7646 - val_loss: 9.2774 - val_mae: 2.3283 - val_mse: 9.2774\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1693 - mae: 1.0238 - mse: 2.1693 - val_loss: 8.2766 - val_mae: 2.1800 - val_mse: 8.2766\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5311 - mae: 0.8165 - mse: 1.5311 - val_loss: 8.4661 - val_mae: 2.2460 - val_mse: 8.4661\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8622 - mae: 0.8764 - mse: 1.8622 - val_loss: 9.3191 - val_mae: 2.2902 - val_mse: 9.3191\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6608 - mae: 0.7753 - mse: 1.6608 - val_loss: 10.5981 - val_mae: 2.2400 - val_mse: 10.5981\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1903 - mae: 1.0475 - mse: 2.1903 - val_loss: 8.4591 - val_mae: 2.1188 - val_mse: 8.4591\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7440 - mae: 0.8723 - mse: 1.7440 - val_loss: 9.3877 - val_mae: 2.3432 - val_mse: 9.3877\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9295 - mae: 0.9299 - mse: 1.9295 - val_loss: 9.7191 - val_mae: 2.4380 - val_mse: 9.7191\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9241 - mae: 0.8718 - mse: 1.9241 - val_loss: 8.7855 - val_mae: 2.2596 - val_mse: 8.7855\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4005 - mae: 0.7333 - mse: 1.4005 - val_loss: 8.3644 - val_mae: 2.1665 - val_mse: 8.3644\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4681 - mae: 0.7409 - mse: 1.4681 - val_loss: 7.7343 - val_mae: 2.0313 - val_mse: 7.7343\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5321 - mae: 0.7815 - mse: 1.5321 - val_loss: 10.1644 - val_mae: 2.2207 - val_mse: 10.1644\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1333 - mae: 0.9415 - mse: 2.1333 - val_loss: 9.1024 - val_mae: 2.3077 - val_mse: 9.1024\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3006 - mae: 0.7132 - mse: 1.3006 - val_loss: 9.4737 - val_mae: 2.3943 - val_mse: 9.4737\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9656 - mae: 0.8939 - mse: 1.9656 - val_loss: 8.2283 - val_mae: 2.1168 - val_mse: 8.2283\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5112 - mae: 0.8076 - mse: 1.5112 - val_loss: 10.3259 - val_mae: 2.5154 - val_mse: 10.3259\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6170 - mae: 0.8029 - mse: 1.6170 - val_loss: 8.4888 - val_mae: 2.1520 - val_mse: 8.4888\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6446 - mae: 0.8223 - mse: 1.6446 - val_loss: 8.6133 - val_mae: 2.2271 - val_mse: 8.6133\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4599 - mae: 0.7723 - mse: 1.4599 - val_loss: 8.9661 - val_mae: 2.3153 - val_mse: 8.9661\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9326 - mae: 0.9274 - mse: 1.9326 - val_loss: 8.8011 - val_mae: 2.2553 - val_mse: 8.8011\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4771 - mae: 0.7356 - mse: 1.4771 - val_loss: 8.4567 - val_mae: 2.1881 - val_mse: 8.4567\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2665 - mae: 1.0102 - mse: 2.2665 - val_loss: 10.7618 - val_mae: 2.5177 - val_mse: 10.7618\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4769 - mae: 0.7639 - mse: 1.4769 - val_loss: 8.6663 - val_mae: 2.1379 - val_mse: 8.6663\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9929 - mae: 0.8974 - mse: 1.9929 - val_loss: 9.1611 - val_mae: 2.3578 - val_mse: 9.1611\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6209 - mae: 0.8318 - mse: 1.6209 - val_loss: 8.1452 - val_mae: 2.1473 - val_mse: 8.1452\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8327 - mae: 0.8296 - mse: 1.8327 - val_loss: 8.3254 - val_mae: 2.1214 - val_mse: 8.3254\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8617 - mae: 0.8744 - mse: 1.8617 - val_loss: 9.1646 - val_mae: 2.1497 - val_mse: 9.1646\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1696 - mae: 0.9949 - mse: 2.1696 - val_loss: 9.4746 - val_mae: 2.3317 - val_mse: 9.4746\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5617 - mae: 0.8308 - mse: 1.5617 - val_loss: 8.7831 - val_mae: 2.2108 - val_mse: 8.7831\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7143 - mae: 0.8508 - mse: 1.7143 - val_loss: 9.0729 - val_mae: 2.2970 - val_mse: 9.0729\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5648 - mae: 0.7825 - mse: 1.5648 - val_loss: 9.5238 - val_mae: 2.1355 - val_mse: 9.5238\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3948 - mae: 1.0518 - mse: 2.3948 - val_loss: 8.8903 - val_mae: 2.1908 - val_mse: 8.8903\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4550 - mae: 0.7830 - mse: 1.4550 - val_loss: 9.2340 - val_mae: 2.3248 - val_mse: 9.2340\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5906 - mae: 0.7605 - mse: 1.5906 - val_loss: 9.2421 - val_mae: 2.1101 - val_mse: 9.2421\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7311 - mae: 0.8756 - mse: 1.7311 - val_loss: 8.2914 - val_mae: 2.1799 - val_mse: 8.2914\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2857 - mae: 0.7210 - mse: 1.2857 - val_loss: 9.5120 - val_mae: 2.1829 - val_mse: 9.5120\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4833 - mae: 0.7552 - mse: 1.4833 - val_loss: 9.0147 - val_mae: 2.2593 - val_mse: 9.0147\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3304 - mae: 0.6859 - mse: 1.3304 - val_loss: 10.1142 - val_mae: 2.1824 - val_mse: 10.1142\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6205 - mae: 1.1097 - mse: 2.6205 - val_loss: 8.4314 - val_mae: 2.0930 - val_mse: 8.4314\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4760 - mae: 0.7863 - mse: 1.4760 - val_loss: 9.0457 - val_mae: 2.2222 - val_mse: 9.0457\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5822 - mae: 0.7940 - mse: 1.5822 - val_loss: 8.5764 - val_mae: 2.1370 - val_mse: 8.5764\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9143 - mae: 0.8632 - mse: 1.9143 - val_loss: 10.8144 - val_mae: 2.5171 - val_mse: 10.8144\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9232 - mae: 1.1764 - mse: 2.9232 - val_loss: 10.9519 - val_mae: 2.5467 - val_mse: 10.9519\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9020 - mae: 0.8974 - mse: 1.9020 - val_loss: 8.8272 - val_mae: 2.2497 - val_mse: 8.8272\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4294 - mae: 0.7263 - mse: 1.4294 - val_loss: 9.0448 - val_mae: 2.3047 - val_mse: 9.0448\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3366 - mae: 1.0106 - mse: 2.3366 - val_loss: 8.5727 - val_mae: 2.1900 - val_mse: 8.5727\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7149 - mae: 0.8638 - mse: 1.7149 - val_loss: 9.6592 - val_mae: 2.3554 - val_mse: 9.6592\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5182 - mae: 0.7786 - mse: 1.5182 - val_loss: 10.1215 - val_mae: 2.4510 - val_mse: 10.1215\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6018 - mae: 0.8255 - mse: 1.6018 - val_loss: 10.0167 - val_mae: 2.3827 - val_mse: 10.0167\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5888 - mae: 0.7292 - mse: 1.5888 - val_loss: 9.9133 - val_mae: 2.1760 - val_mse: 9.9133\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6771 - mae: 0.8347 - mse: 1.6771 - val_loss: 8.2376 - val_mae: 2.1406 - val_mse: 8.2376\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8136 - mae: 0.8330 - mse: 1.8136 - val_loss: 12.0930 - val_mae: 2.7065 - val_mse: 12.0930\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5572 - mae: 1.1191 - mse: 2.5572 - val_loss: 10.9407 - val_mae: 2.5096 - val_mse: 10.9407\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5284 - mae: 0.7961 - mse: 1.5284 - val_loss: 8.8541 - val_mae: 2.2097 - val_mse: 8.8541\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2957 - mae: 0.7135 - mse: 1.2957 - val_loss: 8.5382 - val_mae: 2.1656 - val_mse: 8.5382\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4198 - mae: 0.7721 - mse: 1.4198 - val_loss: 8.9582 - val_mae: 2.2566 - val_mse: 8.9582\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4786 - mae: 0.7184 - mse: 1.4786 - val_loss: 8.2346 - val_mae: 2.1626 - val_mse: 8.2346\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6255 - mae: 0.8330 - mse: 1.6255 - val_loss: 9.9822 - val_mae: 2.2826 - val_mse: 9.9822\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7674 - mae: 0.9294 - mse: 1.7674 - val_loss: 8.6673 - val_mae: 2.1738 - val_mse: 8.6673\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0675 - mae: 0.9329 - mse: 2.0675 - val_loss: 9.7519 - val_mae: 2.3841 - val_mse: 9.7519\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3646 - mae: 0.7248 - mse: 1.3646 - val_loss: 9.5101 - val_mae: 2.3623 - val_mse: 9.5101\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5092 - mae: 0.7953 - mse: 1.5092 - val_loss: 9.2923 - val_mae: 2.3380 - val_mse: 9.2923\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3155 - mae: 0.7021 - mse: 1.3155 - val_loss: 8.8938 - val_mae: 2.2198 - val_mse: 8.8938\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6644 - mae: 0.8323 - mse: 1.6644 - val_loss: 9.8485 - val_mae: 2.4328 - val_mse: 9.8485\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3774 - mae: 0.7473 - mse: 1.3774 - val_loss: 9.8895 - val_mae: 2.4253 - val_mse: 9.8895\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6519 - mae: 0.8630 - mse: 1.6519 - val_loss: 8.9260 - val_mae: 2.1412 - val_mse: 8.9260\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6027 - mae: 0.8293 - mse: 1.6027 - val_loss: 8.6832 - val_mae: 2.1882 - val_mse: 8.6832\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5264 - mae: 0.7573 - mse: 1.5264 - val_loss: 9.0348 - val_mae: 2.2644 - val_mse: 9.0348\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8779 - mae: 0.9198 - mse: 1.8779 - val_loss: 8.2363 - val_mae: 2.1185 - val_mse: 8.2363\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3388 - mae: 0.7422 - mse: 1.3388 - val_loss: 9.8916 - val_mae: 2.4455 - val_mse: 9.8916\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6809 - mae: 0.8736 - mse: 1.6809 - val_loss: 8.6100 - val_mae: 2.1903 - val_mse: 8.6100\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3874 - mae: 0.7781 - mse: 1.3874 - val_loss: 9.7959 - val_mae: 2.3649 - val_mse: 9.7959\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4382 - mae: 0.7501 - mse: 1.4382 - val_loss: 9.1861 - val_mae: 2.3277 - val_mse: 9.1861\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7543 - mae: 0.8249 - mse: 1.7543 - val_loss: 9.9312 - val_mae: 2.4073 - val_mse: 9.9312\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5001 - mae: 0.7871 - mse: 1.5001 - val_loss: 9.5029 - val_mae: 2.3112 - val_mse: 9.5029\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3662 - mae: 0.7196 - mse: 1.3662 - val_loss: 9.2451 - val_mae: 2.3213 - val_mse: 9.2451\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4380 - mae: 0.7527 - mse: 1.4380 - val_loss: 8.8719 - val_mae: 2.2362 - val_mse: 8.8719\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3760 - mae: 0.7422 - mse: 1.3760 - val_loss: 10.2853 - val_mae: 2.1989 - val_mse: 10.2853\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.9822 - mae: 1.1253 - mse: 2.9822 - val_loss: 8.6629 - val_mae: 2.1912 - val_mse: 8.6629\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3386 - mae: 0.7009 - mse: 1.3386 - val_loss: 8.8678 - val_mae: 2.2364 - val_mse: 8.8678\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3055 - mae: 0.6890 - mse: 1.3055 - val_loss: 8.5868 - val_mae: 2.1661 - val_mse: 8.5868\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3167 - mae: 0.6744 - mse: 1.3167 - val_loss: 10.6304 - val_mae: 2.5170 - val_mse: 10.6304\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8263 - mae: 0.8919 - mse: 1.8263 - val_loss: 9.0578 - val_mae: 2.2030 - val_mse: 9.0578\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1421 - mae: 1.0125 - mse: 2.1421 - val_loss: 8.3776 - val_mae: 2.1401 - val_mse: 8.3776\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3704 - mae: 0.7348 - mse: 1.3704 - val_loss: 8.5350 - val_mae: 2.1731 - val_mse: 8.5350\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4889 - mae: 0.7245 - mse: 1.4889 - val_loss: 9.9398 - val_mae: 2.1872 - val_mse: 9.9398\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5569 - mae: 0.8089 - mse: 1.5569 - val_loss: 8.4739 - val_mae: 2.1712 - val_mse: 8.4739\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4423 - mae: 0.7669 - mse: 1.4423 - val_loss: 8.4459 - val_mae: 2.2021 - val_mse: 8.4459\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4697 - mae: 0.7371 - mse: 1.4697 - val_loss: 8.7368 - val_mae: 2.1869 - val_mse: 8.7368\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3280 - mae: 0.7044 - mse: 1.3280 - val_loss: 9.1259 - val_mae: 2.2701 - val_mse: 9.1259\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5949 - mae: 0.7822 - mse: 1.5949 - val_loss: 9.2325 - val_mae: 2.3074 - val_mse: 9.2325\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3506 - mae: 0.6955 - mse: 1.3506 - val_loss: 9.0218 - val_mae: 2.2303 - val_mse: 9.0218\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6636 - mae: 0.7833 - mse: 1.6636 - val_loss: 8.8936 - val_mae: 2.2296 - val_mse: 8.8936\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5358 - mae: 0.7960 - mse: 1.5358 - val_loss: 10.0230 - val_mae: 2.4013 - val_mse: 10.0230\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3333 - mae: 0.7395 - mse: 1.3333 - val_loss: 9.9383 - val_mae: 2.4010 - val_mse: 9.9383\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6288 - mae: 0.8291 - mse: 1.6288 - val_loss: 8.7452 - val_mae: 2.1965 - val_mse: 8.7452\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4551 - mae: 1.0082 - mse: 2.4551 - val_loss: 9.2562 - val_mae: 2.2689 - val_mse: 9.2562\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5144 - mae: 0.8080 - mse: 1.5144 - val_loss: 9.1530 - val_mae: 2.2660 - val_mse: 9.1530\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3723 - mae: 0.7117 - mse: 1.3723 - val_loss: 8.3523 - val_mae: 2.1312 - val_mse: 8.3523\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6796 - mae: 0.8578 - mse: 1.6796 - val_loss: 9.1661 - val_mae: 2.2289 - val_mse: 9.1661\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0693 - mae: 0.9911 - mse: 2.0693 - val_loss: 10.4520 - val_mae: 2.2365 - val_mse: 10.4520\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2330 - mae: 0.9757 - mse: 2.2330 - val_loss: 10.7134 - val_mae: 2.4505 - val_mse: 10.7134\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6835 - mae: 1.1471 - mse: 2.6835 - val_loss: 10.2783 - val_mae: 2.5576 - val_mse: 10.2783\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6751 - mae: 0.8648 - mse: 1.6751 - val_loss: 8.3149 - val_mae: 2.1517 - val_mse: 8.3149\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3901 - mae: 0.7496 - mse: 1.3901 - val_loss: 8.4007 - val_mae: 2.1380 - val_mse: 8.4007\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4283 - mae: 0.8035 - mse: 1.4283 - val_loss: 9.1805 - val_mae: 2.2576 - val_mse: 9.1805\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3105 - mae: 0.7300 - mse: 1.3105 - val_loss: 8.6706 - val_mae: 2.2106 - val_mse: 8.6706\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4135 - mae: 0.7083 - mse: 1.4135 - val_loss: 8.7864 - val_mae: 2.1694 - val_mse: 8.7864\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5966 - mae: 0.7914 - mse: 1.5966 - val_loss: 10.2091 - val_mae: 2.4551 - val_mse: 10.2091\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5720 - mae: 0.8030 - mse: 1.5720 - val_loss: 8.2492 - val_mae: 2.1789 - val_mse: 8.2492\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7348 - mae: 0.8894 - mse: 1.7348 - val_loss: 8.6330 - val_mae: 2.1436 - val_mse: 8.6330\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3731 - mae: 0.7480 - mse: 1.3731 - val_loss: 8.5234 - val_mae: 2.1767 - val_mse: 8.5234\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2922 - mae: 0.6844 - mse: 1.2922 - val_loss: 8.3402 - val_mae: 2.0584 - val_mse: 8.3402\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2893 - mae: 0.6911 - mse: 1.2893 - val_loss: 9.4039 - val_mae: 2.3582 - val_mse: 9.4039\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6671 - mae: 0.7979 - mse: 1.6671 - val_loss: 9.3390 - val_mae: 2.2782 - val_mse: 9.3390\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6610 - mae: 0.8318 - mse: 1.6610 - val_loss: 9.0978 - val_mae: 2.2372 - val_mse: 9.0978\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3382 - mae: 0.7331 - mse: 1.3382 - val_loss: 8.4808 - val_mae: 2.1327 - val_mse: 8.4808\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4155 - mae: 0.7938 - mse: 1.4155 - val_loss: 9.3298 - val_mae: 2.3528 - val_mse: 9.3298\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2858 - mae: 0.7019 - mse: 1.2858 - val_loss: 10.3700 - val_mae: 2.2644 - val_mse: 10.3700\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5845 - mae: 0.8338 - mse: 1.5845 - val_loss: 8.8934 - val_mae: 2.1423 - val_mse: 8.8934\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3459 - mae: 0.7115 - mse: 1.3459 - val_loss: 9.6978 - val_mae: 2.3816 - val_mse: 9.6978\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5067 - mae: 0.7567 - mse: 1.5067 - val_loss: 8.8322 - val_mae: 2.2449 - val_mse: 8.8322\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3502 - mae: 0.7248 - mse: 1.3502 - val_loss: 9.2216 - val_mae: 2.3220 - val_mse: 9.2216\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3953 - mae: 0.7688 - mse: 1.3953 - val_loss: 8.6387 - val_mae: 2.1200 - val_mse: 8.6387\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4510 - mae: 0.7421 - mse: 1.4510 - val_loss: 9.5983 - val_mae: 2.2802 - val_mse: 9.5983\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4048 - mae: 0.7228 - mse: 1.4048 - val_loss: 9.3614 - val_mae: 2.2880 - val_mse: 9.3614\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8268 - mae: 0.8905 - mse: 1.8268 - val_loss: 8.9511 - val_mae: 2.2312 - val_mse: 8.9511\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4813 - mae: 0.7752 - mse: 1.4813 - val_loss: 14.4065 - val_mae: 2.9169 - val_mse: 14.4065\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7320 - mae: 0.8112 - mse: 1.7320 - val_loss: 8.8586 - val_mae: 2.2446 - val_mse: 8.8586\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2223 - mae: 0.6887 - mse: 1.2223 - val_loss: 8.7652 - val_mae: 2.2273 - val_mse: 8.7652\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4194 - mae: 0.6881 - mse: 1.4194 - val_loss: 9.4439 - val_mae: 2.1260 - val_mse: 9.4439\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8302 - mae: 0.8919 - mse: 1.8302 - val_loss: 10.1057 - val_mae: 2.4839 - val_mse: 10.1057\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3912 - mae: 0.7740 - mse: 1.3912 - val_loss: 8.8352 - val_mae: 2.2375 - val_mse: 8.8352\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2005 - mae: 0.9842 - mse: 2.2005 - val_loss: 8.9988 - val_mae: 2.2163 - val_mse: 8.9988\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4800 - mae: 0.8052 - mse: 1.4800 - val_loss: 8.2350 - val_mae: 2.1099 - val_mse: 8.2350\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6165 - mae: 0.7649 - mse: 1.6165 - val_loss: 9.0416 - val_mae: 2.1477 - val_mse: 9.0416\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4674 - mae: 0.7923 - mse: 1.4674 - val_loss: 8.4998 - val_mae: 2.1748 - val_mse: 8.4998\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3405 - mae: 0.7114 - mse: 1.3405 - val_loss: 8.5582 - val_mae: 2.1586 - val_mse: 8.5582\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2303 - mae: 0.6684 - mse: 1.2303 - val_loss: 8.9275 - val_mae: 2.2649 - val_mse: 8.9275\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1796 - mae: 0.6778 - mse: 1.1796 - val_loss: 9.6752 - val_mae: 2.3609 - val_mse: 9.6752\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4322 - mae: 0.7905 - mse: 1.4322 - val_loss: 9.4413 - val_mae: 2.1777 - val_mse: 9.4413\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3851 - mae: 0.7016 - mse: 1.3851 - val_loss: 8.9322 - val_mae: 2.2247 - val_mse: 8.9322\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6360 - mae: 0.7761 - mse: 1.6360 - val_loss: 8.6778 - val_mae: 2.1776 - val_mse: 8.6778\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4751 - mae: 1.0161 - mse: 2.4751 - val_loss: 8.5770 - val_mae: 2.1792 - val_mse: 8.5770\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4675 - mae: 0.7852 - mse: 1.4675 - val_loss: 9.4847 - val_mae: 2.2811 - val_mse: 9.4847\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3805 - mae: 0.7131 - mse: 1.3805 - val_loss: 10.8820 - val_mae: 2.5525 - val_mse: 10.8820\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7367 - mae: 0.8527 - mse: 1.7367 - val_loss: 8.9409 - val_mae: 2.1991 - val_mse: 8.9409\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3884 - mae: 0.7291 - mse: 1.3884 - val_loss: 8.5704 - val_mae: 2.1713 - val_mse: 8.5704\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4187 - mae: 0.6885 - mse: 1.4187 - val_loss: 8.3467 - val_mae: 2.1414 - val_mse: 8.3467\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2161 - mae: 0.6705 - mse: 1.2161 - val_loss: 9.0108 - val_mae: 2.2018 - val_mse: 9.0108\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2482 - mae: 0.6514 - mse: 1.2482 - val_loss: 8.9667 - val_mae: 2.2014 - val_mse: 8.9667\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1429 - mae: 1.0162 - mse: 2.1429 - val_loss: 8.8732 - val_mae: 2.2176 - val_mse: 8.8732\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2735 - mae: 0.7436 - mse: 1.2735 - val_loss: 8.7675 - val_mae: 2.1922 - val_mse: 8.7675\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4756 - mae: 0.7541 - mse: 1.4756 - val_loss: 9.3972 - val_mae: 2.2925 - val_mse: 9.3972\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1778 - mae: 0.6524 - mse: 1.1778 - val_loss: 9.6933 - val_mae: 2.1568 - val_mse: 9.6933\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5634 - mae: 0.8130 - mse: 1.5634 - val_loss: 8.6292 - val_mae: 2.1625 - val_mse: 8.6292\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5042 - mae: 0.7862 - mse: 1.5042 - val_loss: 8.8237 - val_mae: 2.1691 - val_mse: 8.8237\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4081 - mae: 0.7274 - mse: 1.4081 - val_loss: 9.4105 - val_mae: 2.3153 - val_mse: 9.4105\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5317 - mae: 0.7437 - mse: 1.5317 - val_loss: 11.4862 - val_mae: 2.5892 - val_mse: 11.4862\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5602 - mae: 1.1140 - mse: 2.5602 - val_loss: 8.9309 - val_mae: 2.1050 - val_mse: 8.9309\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1274 - mae: 1.0082 - mse: 2.1274 - val_loss: 9.0439 - val_mae: 2.2707 - val_mse: 9.0439\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4352 - mae: 0.7453 - mse: 1.4352 - val_loss: 9.0189 - val_mae: 2.1864 - val_mse: 9.0189\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2157 - mae: 0.9838 - mse: 2.2157 - val_loss: 11.2214 - val_mae: 2.6925 - val_mse: 11.2214\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4395 - mae: 0.8004 - mse: 1.4395 - val_loss: 9.6323 - val_mae: 2.2098 - val_mse: 9.6323\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6531 - mae: 0.7796 - mse: 1.6531 - val_loss: 9.3069 - val_mae: 2.1581 - val_mse: 9.3069\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4469 - mae: 0.7561 - mse: 1.4469 - val_loss: 9.6924 - val_mae: 2.2383 - val_mse: 9.6924\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7632 - mae: 0.8824 - mse: 1.7632 - val_loss: 9.4048 - val_mae: 2.2981 - val_mse: 9.4048\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2630 - mae: 0.7099 - mse: 1.2630 - val_loss: 9.3915 - val_mae: 2.3112 - val_mse: 9.3915\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2270 - mae: 0.6520 - mse: 1.2270 - val_loss: 8.6000 - val_mae: 2.1243 - val_mse: 8.6000\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1784 - mae: 0.6532 - mse: 1.1784 - val_loss: 8.7079 - val_mae: 2.1882 - val_mse: 8.7079\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7868 - mae: 0.7821 - mse: 1.7868 - val_loss: 10.7837 - val_mae: 2.5687 - val_mse: 10.7837\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7026 - mae: 0.8416 - mse: 1.7026 - val_loss: 15.3158 - val_mae: 3.0564 - val_mse: 15.3158\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2723 - mae: 1.0584 - mse: 2.2723 - val_loss: 9.7041 - val_mae: 2.3674 - val_mse: 9.7041\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4571 - mae: 0.7631 - mse: 1.4571 - val_loss: 8.9206 - val_mae: 2.1321 - val_mse: 8.9206\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2480 - mae: 0.6908 - mse: 1.2480 - val_loss: 9.7009 - val_mae: 2.3459 - val_mse: 9.7009\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4685 - mae: 0.7372 - mse: 1.4685 - val_loss: 8.8359 - val_mae: 2.1509 - val_mse: 8.8359\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5824 - mae: 0.7523 - mse: 1.5824 - val_loss: 12.7139 - val_mae: 2.7981 - val_mse: 12.7139\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6069 - mae: 0.7997 - mse: 1.6069 - val_loss: 9.1540 - val_mae: 2.2455 - val_mse: 9.1540\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3585 - mae: 0.7653 - mse: 1.3585 - val_loss: 9.0733 - val_mae: 2.2594 - val_mse: 9.0733\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3092 - mae: 0.7133 - mse: 1.3092 - val_loss: 10.0646 - val_mae: 2.4195 - val_mse: 10.0646\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6704 - mae: 0.8641 - mse: 1.6704 - val_loss: 9.5892 - val_mae: 2.3297 - val_mse: 9.5892\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7434 - mae: 0.8753 - mse: 1.7434 - val_loss: 9.0226 - val_mae: 2.2414 - val_mse: 9.0226\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4074 - mae: 0.7366 - mse: 1.4074 - val_loss: 8.9336 - val_mae: 2.2601 - val_mse: 8.9336\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5200 - mae: 0.7516 - mse: 1.5200 - val_loss: 9.2323 - val_mae: 2.2942 - val_mse: 9.2323\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1980 - mae: 0.6581 - mse: 1.1980 - val_loss: 8.6183 - val_mae: 2.1341 - val_mse: 8.6183\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4534 - mae: 0.7285 - mse: 1.4534 - val_loss: 8.6316 - val_mae: 2.1606 - val_mse: 8.6316\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1325 - mae: 0.6401 - mse: 1.1325 - val_loss: 8.3501 - val_mae: 2.1216 - val_mse: 8.3501\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1721 - mae: 0.6336 - mse: 1.1721 - val_loss: 10.1137 - val_mae: 2.1806 - val_mse: 10.1137\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7713 - mae: 0.8541 - mse: 1.7713 - val_loss: 9.9947 - val_mae: 2.1962 - val_mse: 9.9947\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4445 - mae: 0.7285 - mse: 1.4445 - val_loss: 9.0891 - val_mae: 2.2321 - val_mse: 9.0891\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6362 - mae: 0.7996 - mse: 1.6362 - val_loss: 10.8158 - val_mae: 2.4749 - val_mse: 10.8158\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6334 - mae: 0.7939 - mse: 1.6334 - val_loss: 10.4727 - val_mae: 2.2049 - val_mse: 10.4727\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3449 - mae: 0.6521 - mse: 1.3449 - val_loss: 9.2319 - val_mae: 2.2878 - val_mse: 9.2319\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1501 - mae: 0.6606 - mse: 1.1501 - val_loss: 9.0898 - val_mae: 2.2477 - val_mse: 9.0898\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7507 - mae: 0.7908 - mse: 1.7507 - val_loss: 13.6439 - val_mae: 2.8277 - val_mse: 13.6439\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7754 - mae: 1.2358 - mse: 2.7754 - val_loss: 12.0557 - val_mae: 2.5929 - val_mse: 12.0557\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8429 - mae: 0.8436 - mse: 1.8429 - val_loss: 9.1041 - val_mae: 2.2296 - val_mse: 9.1041\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6129 - mae: 0.7218 - mse: 1.6129 - val_loss: 12.1289 - val_mae: 2.7695 - val_mse: 12.1289\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6351 - mae: 0.7858 - mse: 1.6351 - val_loss: 10.8159 - val_mae: 2.4947 - val_mse: 10.8159\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2834 - mae: 0.7115 - mse: 1.2834 - val_loss: 9.6450 - val_mae: 2.3554 - val_mse: 9.6450\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7557 - mae: 0.8407 - mse: 1.7557 - val_loss: 9.7250 - val_mae: 2.3838 - val_mse: 9.7250\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4303 - mae: 0.7397 - mse: 1.4303 - val_loss: 8.5706 - val_mae: 2.1520 - val_mse: 8.5706\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1650 - mae: 0.6436 - mse: 1.1650 - val_loss: 8.8695 - val_mae: 2.1940 - val_mse: 8.8695\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4718 - mae: 0.7346 - mse: 1.4718 - val_loss: 9.5610 - val_mae: 2.3394 - val_mse: 9.5610\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3326 - mae: 0.7168 - mse: 1.3326 - val_loss: 8.6749 - val_mae: 2.1564 - val_mse: 8.6749\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4039 - mae: 0.7038 - mse: 1.4039 - val_loss: 8.8192 - val_mae: 2.2065 - val_mse: 8.8192\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3045 - mae: 0.6640 - mse: 1.3045 - val_loss: 9.1164 - val_mae: 2.1717 - val_mse: 9.1164\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2753 - mae: 0.6815 - mse: 1.2753 - val_loss: 9.4882 - val_mae: 2.3254 - val_mse: 9.4882\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3194 - mae: 0.7145 - mse: 1.3194 - val_loss: 10.7894 - val_mae: 2.2795 - val_mse: 10.7894\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7185 - mae: 0.8560 - mse: 1.7185 - val_loss: 10.0848 - val_mae: 2.4320 - val_mse: 10.0848\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6660 - mae: 0.8570 - mse: 1.6660 - val_loss: 9.1131 - val_mae: 2.2137 - val_mse: 9.1131\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0148 - mae: 0.8530 - mse: 2.0148 - val_loss: 8.7416 - val_mae: 2.1878 - val_mse: 8.7416\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2213 - mae: 0.6759 - mse: 1.2213 - val_loss: 9.4454 - val_mae: 2.2687 - val_mse: 9.4454\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2828 - mae: 0.6985 - mse: 1.2828 - val_loss: 9.1784 - val_mae: 2.2450 - val_mse: 9.1784\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1588 - mae: 0.6668 - mse: 1.1588 - val_loss: 9.2783 - val_mae: 2.2717 - val_mse: 9.2783\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4019 - mae: 0.7295 - mse: 1.4019 - val_loss: 9.2870 - val_mae: 2.2951 - val_mse: 9.2870\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2767 - mae: 0.7054 - mse: 1.2767 - val_loss: 8.6971 - val_mae: 2.1358 - val_mse: 8.6971\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1295 - mae: 0.6210 - mse: 1.1295 - val_loss: 8.4583 - val_mae: 2.1735 - val_mse: 8.4583\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2561 - mae: 0.6561 - mse: 1.2561 - val_loss: 9.0938 - val_mae: 2.1609 - val_mse: 9.0938\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8493 - mae: 0.9418 - mse: 1.8493 - val_loss: 9.1498 - val_mae: 2.2335 - val_mse: 9.1498\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3665 - mae: 0.6974 - mse: 1.3665 - val_loss: 9.5059 - val_mae: 2.1470 - val_mse: 9.5059\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5030 - mae: 0.7518 - mse: 1.5030 - val_loss: 9.1041 - val_mae: 2.0842 - val_mse: 9.1041\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4572 - mae: 0.7758 - mse: 1.4572 - val_loss: 8.7378 - val_mae: 2.1796 - val_mse: 8.7378\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6903 - mae: 0.8218 - mse: 1.6903 - val_loss: 10.3899 - val_mae: 2.5120 - val_mse: 10.3899\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2029 - mae: 0.6659 - mse: 1.2029 - val_loss: 9.0853 - val_mae: 2.1714 - val_mse: 9.0853\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7351 - mae: 0.8664 - mse: 1.7351 - val_loss: 8.4732 - val_mae: 2.1346 - val_mse: 8.4732\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1928 - mae: 0.9516 - mse: 2.1928 - val_loss: 9.5156 - val_mae: 2.1730 - val_mse: 9.5156\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9180 - mae: 0.9049 - mse: 1.9180 - val_loss: 10.1560 - val_mae: 2.4341 - val_mse: 10.1560\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6718 - mae: 0.8350 - mse: 1.6718 - val_loss: 9.2556 - val_mae: 2.1661 - val_mse: 9.2556\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1760 - mae: 0.7325 - mse: 1.1760 - val_loss: 9.2628 - val_mae: 2.2846 - val_mse: 9.2628\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2242 - mae: 0.6898 - mse: 1.2242 - val_loss: 9.0804 - val_mae: 2.2463 - val_mse: 9.0804\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4737 - mae: 0.7026 - mse: 1.4737 - val_loss: 10.4992 - val_mae: 2.2392 - val_mse: 10.4992\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2154 - mae: 1.0282 - mse: 2.2154 - val_loss: 8.9522 - val_mae: 2.2265 - val_mse: 8.9522\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5093 - mae: 0.7655 - mse: 1.5093 - val_loss: 11.5518 - val_mae: 2.6701 - val_mse: 11.5518\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2754 - mae: 0.9661 - mse: 2.2754 - val_loss: 9.0600 - val_mae: 2.2120 - val_mse: 9.0600\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5707 - mae: 0.7910 - mse: 1.5707 - val_loss: 9.4096 - val_mae: 2.2449 - val_mse: 9.4096\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4496 - mae: 0.8069 - mse: 1.4496 - val_loss: 8.8881 - val_mae: 2.2211 - val_mse: 8.8881\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2068 - mae: 0.6561 - mse: 1.2068 - val_loss: 9.5555 - val_mae: 2.1295 - val_mse: 9.5555\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3843 - mae: 0.7434 - mse: 1.3843 - val_loss: 8.9575 - val_mae: 2.2281 - val_mse: 8.9575\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4703 - mae: 0.7665 - mse: 1.4703 - val_loss: 9.1281 - val_mae: 2.2448 - val_mse: 9.1281\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9287 - mae: 0.8400 - mse: 1.9287 - val_loss: 8.5907 - val_mae: 2.0831 - val_mse: 8.5907\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7238 - mae: 0.7896 - mse: 1.7238 - val_loss: 9.1721 - val_mae: 2.3200 - val_mse: 9.1721\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7678 - mae: 1.1813 - mse: 2.7678 - val_loss: 9.5998 - val_mae: 2.3436 - val_mse: 9.5998\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5214 - mae: 0.8237 - mse: 1.5214 - val_loss: 9.3229 - val_mae: 2.3286 - val_mse: 9.3229\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6909 - mae: 0.8678 - mse: 1.6909 - val_loss: 10.8470 - val_mae: 2.5667 - val_mse: 10.8470\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4141 - mae: 0.7619 - mse: 1.4141 - val_loss: 8.9652 - val_mae: 2.2751 - val_mse: 8.9652\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5794 - mae: 0.8224 - mse: 1.5794 - val_loss: 9.1056 - val_mae: 2.2225 - val_mse: 9.1056\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3512 - mae: 0.7212 - mse: 1.3512 - val_loss: 10.0975 - val_mae: 2.4326 - val_mse: 10.0975\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4390 - mae: 0.7646 - mse: 1.4390 - val_loss: 8.7389 - val_mae: 2.1796 - val_mse: 8.7389\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2588 - mae: 0.6786 - mse: 1.2588 - val_loss: 8.7445 - val_mae: 2.1562 - val_mse: 8.7445\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3052 - mae: 0.6828 - mse: 1.3052 - val_loss: 10.1754 - val_mae: 2.4212 - val_mse: 10.1754\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4558 - mae: 0.7611 - mse: 1.4558 - val_loss: 9.0722 - val_mae: 2.2591 - val_mse: 9.0722\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2583 - mae: 0.7365 - mse: 1.2583 - val_loss: 9.9856 - val_mae: 2.3286 - val_mse: 9.9856\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5515 - mae: 0.7834 - mse: 1.5515 - val_loss: 10.6855 - val_mae: 2.3266 - val_mse: 10.6855\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3436 - mae: 1.0262 - mse: 2.3436 - val_loss: 8.8453 - val_mae: 2.1698 - val_mse: 8.8453\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1867 - mae: 0.6273 - mse: 1.1867 - val_loss: 9.6302 - val_mae: 2.1854 - val_mse: 9.6302\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0572 - mae: 1.0145 - mse: 2.0572 - val_loss: 9.6425 - val_mae: 2.2300 - val_mse: 9.6425\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0902 - mae: 0.9259 - mse: 2.0902 - val_loss: 13.1954 - val_mae: 2.7964 - val_mse: 13.1954\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5219 - mae: 1.0479 - mse: 2.5219 - val_loss: 9.4062 - val_mae: 2.2923 - val_mse: 9.4062\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7560 - mae: 0.8549 - mse: 1.7560 - val_loss: 8.8758 - val_mae: 2.1838 - val_mse: 8.8758\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2338 - mae: 0.6416 - mse: 1.2338 - val_loss: 9.8814 - val_mae: 2.1949 - val_mse: 9.8814\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9491 - mae: 0.8930 - mse: 1.9491 - val_loss: 9.2040 - val_mae: 2.0989 - val_mse: 9.2040\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1496 - mae: 0.6555 - mse: 1.1496 - val_loss: 8.9744 - val_mae: 2.1981 - val_mse: 8.9744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAdSFOWztXqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "dc7c5ca7-a423-4e50-bcba-f7047135e119"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33AUzqFldHAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f437463-4640-455c-af50-cfb93f4353d0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR4RvK3HiUeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "a959cf87-b155-407d-b0e0-8147b339001b"
      },
      "source": [
        "# 데이터 프레임으로 만들기\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>336.815521</td>\n",
              "      <td>15.699776</td>\n",
              "      <td>336.815521</td>\n",
              "      <td>280.240234</td>\n",
              "      <td>15.293508</td>\n",
              "      <td>280.240234</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101.460205</td>\n",
              "      <td>7.533990</td>\n",
              "      <td>101.460205</td>\n",
              "      <td>126.069191</td>\n",
              "      <td>8.929481</td>\n",
              "      <td>126.069191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>167.030319</td>\n",
              "      <td>9.340543</td>\n",
              "      <td>167.030319</td>\n",
              "      <td>443.456238</td>\n",
              "      <td>19.771544</td>\n",
              "      <td>443.456238</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188.419098</td>\n",
              "      <td>11.728955</td>\n",
              "      <td>188.419098</td>\n",
              "      <td>32.933655</td>\n",
              "      <td>4.274022</td>\n",
              "      <td>32.933655</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63.238415</td>\n",
              "      <td>6.013675</td>\n",
              "      <td>63.238415</td>\n",
              "      <td>37.947243</td>\n",
              "      <td>4.515176</td>\n",
              "      <td>37.947243</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2.521884</td>\n",
              "      <td>1.047917</td>\n",
              "      <td>2.521884</td>\n",
              "      <td>9.406240</td>\n",
              "      <td>2.292334</td>\n",
              "      <td>9.406240</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.756034</td>\n",
              "      <td>0.854875</td>\n",
              "      <td>1.756034</td>\n",
              "      <td>8.875791</td>\n",
              "      <td>2.183803</td>\n",
              "      <td>8.875791</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.233756</td>\n",
              "      <td>0.641560</td>\n",
              "      <td>1.233756</td>\n",
              "      <td>9.881400</td>\n",
              "      <td>2.194902</td>\n",
              "      <td>9.881400</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.949136</td>\n",
              "      <td>0.892960</td>\n",
              "      <td>1.949136</td>\n",
              "      <td>9.203988</td>\n",
              "      <td>2.098930</td>\n",
              "      <td>9.203988</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1.149608</td>\n",
              "      <td>0.655486</td>\n",
              "      <td>1.149608</td>\n",
              "      <td>8.974358</td>\n",
              "      <td>2.198051</td>\n",
              "      <td>8.974358</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           loss        mae         mse  ...    val_mae     val_mse  epoch\n",
              "0    336.815521  15.699776  336.815521  ...  15.293508  280.240234      0\n",
              "1    101.460205   7.533990  101.460205  ...   8.929481  126.069191      1\n",
              "2    167.030319   9.340543  167.030319  ...  19.771544  443.456238      2\n",
              "3    188.419098  11.728955  188.419098  ...   4.274022   32.933655      3\n",
              "4     63.238415   6.013675   63.238415  ...   4.515176   37.947243      4\n",
              "..          ...        ...         ...  ...        ...         ...    ...\n",
              "995    2.521884   1.047917    2.521884  ...   2.292334    9.406240    995\n",
              "996    1.756034   0.854875    1.756034  ...   2.183803    8.875791    996\n",
              "997    1.233756   0.641560    1.233756  ...   2.194902    9.881400    997\n",
              "998    1.949136   0.892960    1.949136  ...   2.098930    9.203988    998\n",
              "999    1.149608   0.655486    1.149608  ...   2.198051    8.974358    999\n",
              "\n",
              "[1000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1goFP6Eieek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c1224ef6-aabe-451e-b9bb-ead7a2444464"
      },
      "source": [
        "# 시각화 하기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist['epoch'], hist['mse'])\n",
        "plt.plot(hist['epoch'], hist['val_mse'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXmwxl9pk4ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 주택가격 예측하기_회귀\n",
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj3W0SHQnQBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bf958387-d219-4522-8c08-393b68f07730"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_targets.shape)\n",
        "print(test_targets.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n",
            "(404,)\n",
            "(102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV98qq7Yp6J1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 31
        },
        "outputId": "f71d9729-a1ac-478f-d8d6-2508cfbefc86"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "housing = boston_housing.load_data()\n",
        "\n",
        "housing = pd.DataFrame()\n",
        "housing\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VtYviUTEVDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "2ed724c3-cec4-4c69-f4d3-56c5d5a31b5f"
      },
      "source": [
        "'''x_mean = train_X.mean(axis=0)\n",
        "x_std = train_X.std(axis=0)\n",
        "\n",
        "train_X = train_X - x_mean\n",
        "train_X = train_X / x_std\n",
        "\n",
        "test_X = test_X - x_mean\n",
        "test_X = test_X / x_std\n",
        "\n",
        "###################################\n",
        "y_mean = train_Y.mean(axis=0)\n",
        "y_std = train_Y.std(axis=0)\n",
        "\n",
        "train_Y = train_Y - y_mean\n",
        "train_Y = train_Y / y_std\n",
        "\n",
        "test_Y = test_Y - y_mean\n",
        "test_Y = test_Y / y_std\n",
        "\n",
        "###################################\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(13,)),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss='mse', metrics=\"mse\")\n",
        "model.summary()\n",
        "\n",
        "##################################\n",
        "\n",
        "tf.keras.utils.plot_model(model)\n",
        "\n",
        "##################################\n",
        "\n",
        "history = model.fit(train_X, train_Y, epochs=100, batch_size=32, validation_split=0.25, verbose=1)\n",
        "\n",
        "history.history.keys()\n",
        "\n",
        "##################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss') \n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "##################################\n",
        "\n",
        "#학습하다가 val_loss가 3회 최적화 되지 않으면 종료됨.\n",
        "history = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss')])'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x_mean = train_X.mean(axis=0)\\nx_std = train_X.std(axis=0)\\n\\ntrain_X = train_X - x_mean\\ntrain_X = train_X / x_std\\n\\ntest_X = test_X - x_mean\\ntest_X = test_X / x_std\\n\\n###################################\\ny_mean = train_Y.mean(axis=0)\\ny_std = train_Y.std(axis=0)\\n\\ntrain_Y = train_Y - y_mean\\ntrain_Y = train_Y / y_std\\n\\ntest_Y = test_Y - y_mean\\ntest_Y = test_Y / y_std\\n\\n###################################\\n\\nmodel = tf.keras.Sequential([\\n    tf.keras.layers.Dense(units=64, activation=\\'relu\\', input_shape=(13,)),\\n    tf.keras.layers.Dense(units=32, activation=\\'relu\\'),\\n    tf.keras.layers.Dense(units=1)\\n])\\n\\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss=\\'mse\\', metrics=\"mse\")\\nmodel.summary()\\n\\n##################################\\n\\ntf.keras.utils.plot_model(model)\\n\\n##################################\\n\\nhistory = model.fit(train_X, train_Y, epochs=100, batch_size=32, validation_split=0.25, verbose=1)\\n\\nhistory.history.keys()\\n\\n##################################\\n\\nimport matplotlib.pyplot as plt\\nplt.plot(history.history[\\'loss\\'], \\'b-\\', label=\\'loss\\')\\nplt.plot(history.history[\\'val_loss\\'], \\'r--\\', label=\\'val_loss\\') \\nplt.xlabel(\\'Epoch\\')\\nplt.legend()\\nplt.show()\\n\\n##################################\\n\\n#학습하다가 val_loss가 3회 최적화 되지 않으면 종료됨.\\nhistory = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor=\\'val_loss\\')])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lc2DcYpFEMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "red = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "white = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M5Mn6RqRFUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "63264ce4-f48f-4996-a339-fbadfd8f7526"
      },
      "source": [
        "red.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmo3BuKzRHY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "c5eddd0f-32c6-4f66-c5dc-59e9e8f1b7bb"
      },
      "source": [
        "white.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "1            6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "2            8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "3            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "4            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QGtw65NRJQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "60f41406-3061-4995-93fd-c44b904d94bc"
      },
      "source": [
        "red.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecfwW7TCRLXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "90304b7e-f85a-452e-c86f-ce130b9b8f9d"
      },
      "source": [
        "white.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4898 entries, 0 to 4897\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         4898 non-null   float64\n",
            " 1   volatile acidity      4898 non-null   float64\n",
            " 2   citric acid           4898 non-null   float64\n",
            " 3   residual sugar        4898 non-null   float64\n",
            " 4   chlorides             4898 non-null   float64\n",
            " 5   free sulfur dioxide   4898 non-null   float64\n",
            " 6   total sulfur dioxide  4898 non-null   float64\n",
            " 7   density               4898 non-null   float64\n",
            " 8   pH                    4898 non-null   float64\n",
            " 9   sulphates             4898 non-null   float64\n",
            " 10  alcohol               4898 non-null   float64\n",
            " 11  quality               4898 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 459.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EecHTInMRQOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red['type'] = 0\n",
        "white['type']=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEnx47kHRoI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCfNzvYlRqQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "d9d16e79-f21d-4e72-f846-b063033e779c"
      },
      "source": [
        "wine = pd.concat([red,white],axis=0)\n",
        "wine.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6497 entries, 0 to 4897\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         6497 non-null   float64\n",
            " 1   volatile acidity      6497 non-null   float64\n",
            " 2   citric acid           6497 non-null   float64\n",
            " 3   residual sugar        6497 non-null   float64\n",
            " 4   chlorides             6497 non-null   float64\n",
            " 5   free sulfur dioxide   6497 non-null   float64\n",
            " 6   total sulfur dioxide  6497 non-null   float64\n",
            " 7   density               6497 non-null   float64\n",
            " 8   pH                    6497 non-null   float64\n",
            " 9   sulphates             6497 non-null   float64\n",
            " 10  alcohol               6497 non-null   float64\n",
            " 11  quality               6497 non-null   int64  \n",
            " 12  type                  6497 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 710.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWtZel9FR-wm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "adee974e-7ccb-4e44-dc17-c7e607fbb272"
      },
      "source": [
        "wine.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
              "4893            6.2              0.21         0.29  ...     11.2        6     1\n",
              "4894            6.6              0.32         0.36  ...      9.6        5     1\n",
              "4895            6.5              0.24         0.19  ...      9.4        6     1\n",
              "4896            5.5              0.29         0.30  ...     12.8        7     1\n",
              "4897            6.0              0.21         0.38  ...     11.8        6     1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQR25GJaSY8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d2463e56-01f6-4fd3-93ed-3f3504ee04fc"
      },
      "source": [
        "print(wine['type'][wine['type']==0].count())\n",
        "print(wine['type'][wine['type']==1].count())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1599\n",
            "4898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFAwW5EYdx3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "4b9befdb-61b0-4160-e356-666aae925a67"
      },
      "source": [
        "wine = wine.sample(frac=1) #모든 데이터를 뽑아서 섞음 \n",
        "wine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4639</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.26</td>\n",
              "      <td>12.7</td>\n",
              "      <td>0.049</td>\n",
              "      <td>59.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.99596</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.54</td>\n",
              "      <td>10.5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.040</td>\n",
              "      <td>15.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.99120</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.61</td>\n",
              "      <td>12.1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4770</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.30</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>69.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>0.99705</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1107</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.15</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.029</td>\n",
              "      <td>27.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.99030</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.59</td>\n",
              "      <td>12.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8.1</td>\n",
              "      <td>0.050</td>\n",
              "      <td>42.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.99585</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
              "4639            6.9              0.54         0.26  ...     10.5        6     1\n",
              "1111            8.0              0.18         0.37  ...     12.1        6     1\n",
              "4770            6.8              0.27         0.30  ...      9.6        6     1\n",
              "1107            7.2              0.37         0.15  ...     12.6        7     1\n",
              "761             7.0              0.20         0.38  ...      9.8        6     1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeOXTLf6X0-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6138d8ed-7eb0-43e9-948b-20b0bc830002"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "#wine_np = wine.to_numpy() #numpy로 변경\n",
        "wine_np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.5 ,  0.24,  0.32, ..., 10.4 ,  5.  ,  1.  ],\n",
              "       [ 5.8 ,  0.33,  0.2 , ...,  8.9 ,  5.  ,  1.  ],\n",
              "       [ 8.3 ,  0.4 ,  0.38, ...,  9.2 ,  5.  ,  1.  ],\n",
              "       ...,\n",
              "       [ 8.  ,  0.29,  0.49, ..., 10.8 ,  5.  ,  1.  ],\n",
              "       [10.7 ,  0.9 ,  0.34, ...,  9.3 ,  5.  ,  0.  ],\n",
              "       [ 7.5 ,  0.32,  0.37, ...,  9.3 ,  5.  ,  1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUkPxMMjZcJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#80%로 나누기\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "\n",
        "train_X = wine_np[:train_idx, :-1]\n",
        "train_Y = wine_np[:train_idx, -1]\n",
        "\n",
        "test_X = wine_np[train_idx:, :-1]\n",
        "test_Y = wine_np[train_idx:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEIiLyuuZzUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "878b01aa-496d-4ea0-ea8b-7cc1a165f79e"
      },
      "source": [
        "train_X\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.5 ,  0.24,  0.32, ...,  0.31, 10.4 ,  5.  ],\n",
              "       [ 5.8 ,  0.33,  0.2 , ...,  0.46,  8.9 ,  5.  ],\n",
              "       [ 8.3 ,  0.4 ,  0.38, ...,  0.43,  9.2 ,  5.  ],\n",
              "       ...,\n",
              "       [ 8.4 ,  0.28,  0.4 , ...,  0.46,  9.3 ,  5.  ],\n",
              "       [ 7.9 ,  0.41,  0.37, ...,  0.54, 12.4 ,  7.  ],\n",
              "       [ 5.8 ,  0.39,  0.47, ...,  0.45, 14.  ,  6.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkbjbMtwfEBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "f66fe6b0-f4f6-40c6-8e10-eb138dafee6a"
      },
      "source": [
        "# 원핫\n",
        "import tensorflow as tf\n",
        "\n",
        "# num_classes 는 종류 : 지금은 0과 1만 있음.\n",
        "\n",
        "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes=2) \n",
        "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes=2)\n",
        "\n",
        "train_Y[4:30] # 확인용\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGoloyzufOra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "274ddd9e-89a9-4e6f-a871-33a4288a5000"
      },
      "source": [
        "# 모델만들기\n",
        "\n",
        "# softmax - 분류에서 사용함.\n",
        "# 큰값이 부각되는 효과\n",
        "# 전체 값은 1.0이 됨\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "x = np.arange(-2, 2, 0.01)\n",
        "e_x = math.e ** x\n",
        "\n",
        "plt.axhline(0, color='gray')\n",
        "plt.axvline(0, color='gray')\n",
        "plt.plot(x, x, 'b-', label='y=x')\n",
        "plt.plot(x, e_x, 'g.', label='y=e^x')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4saajqLf1er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "228580ab-f8da-4afa-86af-65bb148ea876"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=48, activation='relu', input_shape=(12,)),\n",
        "  tf.keras.layers.Dense(units=24, activation='relu'),   \n",
        "  tf.keras.layers.Dense(units=12, activation='relu') ,\n",
        "  tf.keras.layers.Dense(units=2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 48)                624       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 24)                1176      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 2)                 26        \n",
            "=================================================================\n",
            "Total params: 2,126\n",
            "Trainable params: 2,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KHZScM2f-2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "43b3c32b-cf92-4699-dfed-666accc3f728"
      },
      "source": [
        "# 분류하고자 하는 label값이 원핫 일경우  : categorical_crossentropy\n",
        "# 측정지표 = accuracy\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.04)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.7014 - accuracy: 0.8835 - val_loss: 0.2180 - val_accuracy: 0.9246\n",
            "Epoch 2/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9343 - val_loss: 0.2180 - val_accuracy: 0.9185\n",
            "Epoch 3/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9374 - val_loss: 0.2037 - val_accuracy: 0.9215\n",
            "Epoch 4/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9371 - val_loss: 0.2193 - val_accuracy: 0.9377\n",
            "Epoch 5/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9341 - val_loss: 0.1817 - val_accuracy: 0.9385\n",
            "Epoch 6/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9433 - val_loss: 0.1818 - val_accuracy: 0.9408\n",
            "Epoch 7/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9412 - val_loss: 0.2039 - val_accuracy: 0.9423\n",
            "Epoch 8/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9615 - val_loss: 0.1673 - val_accuracy: 0.9454\n",
            "Epoch 9/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9636 - val_loss: 0.1427 - val_accuracy: 0.9554\n",
            "Epoch 10/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9659 - val_loss: 0.1197 - val_accuracy: 0.9662\n",
            "Epoch 11/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9720 - val_loss: 0.1136 - val_accuracy: 0.9723\n",
            "Epoch 12/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9687 - val_loss: 0.0951 - val_accuracy: 0.9723\n",
            "Epoch 13/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9736 - val_loss: 0.1274 - val_accuracy: 0.9623\n",
            "Epoch 14/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9648 - val_loss: 0.1696 - val_accuracy: 0.9538\n",
            "Epoch 15/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9697 - val_loss: 0.1068 - val_accuracy: 0.9700\n",
            "Epoch 16/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9743 - val_loss: 0.1079 - val_accuracy: 0.9715\n",
            "Epoch 17/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9692 - val_loss: 0.1247 - val_accuracy: 0.9677\n",
            "Epoch 18/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9772 - val_loss: 0.0942 - val_accuracy: 0.9754\n",
            "Epoch 19/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9743 - val_loss: 0.1183 - val_accuracy: 0.9692\n",
            "Epoch 20/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9731 - val_loss: 0.0852 - val_accuracy: 0.9769\n",
            "Epoch 21/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9695 - val_loss: 0.1636 - val_accuracy: 0.9492\n",
            "Epoch 22/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9541 - val_loss: 0.1261 - val_accuracy: 0.9685\n",
            "Epoch 23/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9702 - val_loss: 0.0972 - val_accuracy: 0.9731\n",
            "Epoch 24/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9743 - val_loss: 0.0947 - val_accuracy: 0.9762\n",
            "Epoch 25/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9779 - val_loss: 0.0805 - val_accuracy: 0.9792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknmUcUbiaZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3e498218-84a5-4745-977b-17d9ad01a134"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrVbn4_1id3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "854857ac-8ebf-4150-92b4-3d8ef66d2ab0"
      },
      "source": [
        "import numpy as np\n",
        "# 훈련된 모델로 예측값 수행\n",
        "results = model.predict(test_X)\n",
        "\n",
        "# 예측값 중에서 가장 큰 값의 인덱스값을 b에 넣음\n",
        "b = np.argmax(results, axis=-1)\n",
        "\n",
        "print(b[:10])  # 예측한 값의 결과\n",
        "print(\"-----------\")\n",
        "print(test_Y[:10])  # 실제 값의 결과"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 0 1]\n",
            "-----------\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM103F3FjmNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}